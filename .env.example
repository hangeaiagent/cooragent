# LLM Environment variables

# Reasoning LLM (for complex reasoning tasks)
# If you're using your local Ollama, replace the model name after the slash and base url then you're good to go.
# For wider model support, read https://docs.litellm.ai/docs/providers.
REASONING_API_KEY=sk-#######
REASONING_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
REASONING_MODEL=qwen-max-latest

# Non-reasoning LLM (for straightforward tasks)
BASIC_API_KEY=sk-#######
BASIC_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
BASIC_MODEL=qwen-max-latest

 CODE_API_KEY=sk-#######
CODE_BASE_URL=https://api.deepseek.com/v1
CODE_MODEL=deepseek-chat

# VIDEO_MODEL=
# Vision-language LLM (for tasks requiring visual understanding)
VL_API_KEY=sk-#######
VL_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
VL_MODEL=qwen2.5-vl-72b-instruct

# Application Settings
DEBUG=true
APP_ENV=development

# browser is default to False, for it's time consuming
USE_BROWSER=true

# Add other environment variables as needed
TAVILY_API_KEY=tvly-dev-¥¥¥¥
JINA_API_KEY=jina_¥¥¥¥¥ # Optional, default is None

# turn off for collecting anonymous usage information
# ANONYMIZED_TELEMETRY=

# SLACK_USER_TOKEN=

#SILICONFLOW_API_KEY=

# Whether to use the agent of MCP tool, default to False
 MCP_AGENT=True

# The maximum execution steps of an agent,the default is 25,Non essential adjustments are not recommended
 MAX_STEPS = 25