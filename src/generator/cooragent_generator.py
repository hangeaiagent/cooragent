"""
åŸºäºŽCooragentæž¶æž„çš„é¡¹ç›®ä»£ç ç”Ÿæˆå™¨ - å¢žå¼ºç‰ˆ

è¯¥æ¨¡å—å®žçŽ°äº†ä»Žç”¨æˆ·éœ€æ±‚åˆ°å®Œæ•´Cooragenté¡¹ç›®çš„è‡ªåŠ¨ç”Ÿæˆæµç¨‹
åŒ…å«å·¥ä½œæµåŒæ­¥åŒ–ã€åŠ¨æ€ç»„ä»¶åˆ†æžã€MCPç”Ÿæ€é›†æˆç­‰å¢žå¼ºåŠŸèƒ½
"""

import asyncio
import json
import logging
import shutil
import time
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

import aiofiles

from src.interface.agent import Agent, TaskType
from src.manager import agent_manager
from src.workflow.process import run_agent_workflow
from src.generator.config_generator import ConfigGenerator
from src.utils.path_utils import get_project_root

logger = logging.getLogger(__name__)


class DynamicComponentAnalyzer:
    """åŠ¨æ€ç»„ä»¶éœ€æ±‚åˆ†æžå™¨"""
    
    def __init__(self):
        self.core_components = {
            "interface": ["agent.py", "workflow.py", "serializer.py", "mcp.py", "__init__.py"],
            "workflow": [
                "graph.py", "process.py", "cache.py", "template.py", 
                "coor_task.py", "agent_factory.py", "dynamic.py", "manager.py",
                "polish_task.py", "__init__.py"
            ],
            "manager": ["agents.py", "mcp.py", "__init__.py"],
            "llm": ["llm.py", "agents.py", "__init__.py"],
            "utils": ["path_utils.py", "content_process.py", "chinese_names.py", "file_cleaner.py", "__init__.py"],
            "service": ["server.py", "session.py", "env.py", "tool_tracker.py", "__init__.py"],
            "prompts": ["template.py", "__init__.py"]
        }
        
        self.tool_dependencies = {
            "tavily_tool": ["search.py", "decorators.py"],
            "python_repl_tool": ["python_repl.py", "decorators.py"],
            "bash_tool": ["bash_tool.py", "decorators.py"],
            "crawl_tool": ["crawl.py", "crawler/", "decorators.py"],
            "browser_tool": ["browser.py", "browser_decorators.py", "decorators.py"],
            "excel_tool": ["excel/", "decorators.py"],
            "gmail_tool": ["gmail.py", "decorators.py"],
            "slack_tool": ["slack.py", "decorators.py"],
            "video_tool": ["video.py", "decorators.py"],
            "file_management_tool": ["file_management.py", "decorators.py"],
            "avatar_tool": ["avatar_tool.py", "decorators.py"],
            "office365_tool": ["office365.py", "decorators.py"],
            "web_preview_tool": ["web_preview_tool.py", "web_preview/", "decorators.py"],
            "websocket_tool": ["websocket_manager.py", "decorators.py"],
            # GitHubç‰ˆæœ¬çš„MCPå·¥å…·
            "searchFlightItineraries": ["decorators.py"],
            "flight_search": ["decorators.py"],
            "search_flights": ["decorators.py"],
            "maps_direction_driving": ["decorators.py"],
            "maps_direction_transit": ["decorators.py"],
            "maps_direction_walking": ["decorators.py"],
            "maps_distance": ["decorators.py"],
            "maps_geo": ["decorators.py"],
            "maps_regeocode": ["decorators.py"],
            "maps_ip_location": ["decorators.py"],
            "maps_around_search": ["decorators.py"],
            "maps_search_detail": ["decorators.py"],
            "maps_text_search": ["decorators.py"],
            "amap_tool": ["decorators.py"],
            "mcp_doc": ["MCP-Doc/", "decorators.py"],
            "document_processor": ["MCP-Doc/", "decorators.py"],
            "mcp_image_downloader": ["mcp-image-downloader/", "decorators.py"],
            "image_downloader": ["mcp-image-downloader/", "decorators.py"],
            "decorators": ["decorators.py"]
        }
        
        self.mcp_dependencies = {
            "mcp_doc": ["MCP-Doc/"],
            "mcp_image_downloader": ["mcp-image-downloader/"],
            "filesystem": ["éœ€è¦mcpé…ç½®"]
        }
    
    async def analyze_requirements(self, agents_config: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ¨æ€åˆ†æžé¡¹ç›®éœ€æ±‚"""
        
        agents = agents_config["agents"]
        tools_used = agents_config["tools_used"]
        
        requirements = {
            "core_components": self.core_components.copy(),
            "tool_components": {},
            "mcp_components": {},
            "llm_requirements": {},
            "workflow_requirements": {},
            "deployment_requirements": {}
        }
        
        # åˆ†æžLLMéœ€æ±‚
        llm_types = set(agent.llm_type for agent in agents)
        requirements["llm_requirements"] = {
            "types": list(llm_types),
            "reasoning_enabled": "reasoning" in llm_types,
            "vision_enabled": "vision" in llm_types,
            "code_enabled": "code" in llm_types
        }
        
        # æ ¹æ®LLMç±»åž‹æ·»åŠ ç»„ä»¶
        if "reasoning" in llm_types:
            requirements["core_components"]["llm"].append("reasoning_config.py")
        if "vision" in llm_types:
            requirements["core_components"]["llm"].append("vision_config.py")
        
        # åˆ†æžå·¥å…·éœ€æ±‚
        for tool in tools_used:
            if tool in self.tool_dependencies:
                requirements["tool_components"][tool] = self.tool_dependencies[tool]
            elif tool.startswith("mcp_"):
                requirements["mcp_components"][tool] = self.mcp_dependencies.get(tool, [])
        
        # ç¡®ä¿decorators.pyæ€»æ˜¯è¢«åŒ…å«ï¼Œæ‰€æœ‰å·¥å…·éƒ½éœ€è¦å®ƒ
        if requirements["tool_components"]:
            requirements["tool_components"]["decorators"] = ["decorators.py"]
        
        # å¦‚æžœä½¿ç”¨äº†MCPå·¥å…·ï¼Œéœ€è¦MCPç®¡ç†å™¨
        if requirements["mcp_components"]:
            requirements["core_components"]["manager"].append("mcp.py")
        
        # åˆ†æžå·¥ä½œæµéœ€æ±‚
        agent_count = len(agents)
        requirements["workflow_requirements"] = {
            "agent_count": agent_count,
            "needs_factory": any(agent.agent_name != "agent_factory" for agent in agents),
            "needs_cache": agent_count > 1,
            "needs_state_management": True,
            "complexity": "complex" if agent_count > 3 else "simple"
        }
        
        # åˆ†æžéƒ¨ç½²éœ€æ±‚
        requirements["deployment_requirements"] = {
            "needs_docker": True,
            "needs_env_config": True,
            "needs_startup_scripts": True,
            "needs_nginx": agent_count > 3,
            "estimated_memory": f"{max(512, agent_count * 128)}MB"
        }
        
        return requirements


class MCPEcosystemIntegrator:
    """MCPç”Ÿæ€ç³»ç»Ÿé›†æˆå™¨"""
    
    async def integrate_mcp_ecosystem(self, project_path: Path, tools_used: List[str], progress_callback=None):
        """é›†æˆå®Œæ•´çš„MCPç”Ÿæ€ç³»ç»Ÿ"""
        
        if progress_callback:
            await progress_callback("é›†æˆMCPç”Ÿæ€ç³»ç»Ÿ...", 70, "MCPé›†æˆ", "é…ç½®MCPå·¥å…·å’ŒæœåŠ¡å™¨")
        
        # 1. å¤åˆ¶MCPç®¡ç†å™¨
        await self._copy_mcp_manager(project_path)
        
        # 2. ç”ŸæˆMCPé…ç½®æ–‡ä»¶
        await self._generate_mcp_config(project_path, tools_used)
        
        # 3. å¤åˆ¶MCPå·¥å…·æœåŠ¡å™¨
        await self._copy_mcp_tools(project_path, tools_used)
        
        # 4. ç”ŸæˆMCPå®‰è£…è„šæœ¬
        await self._generate_mcp_setup_scripts(project_path, tools_used)
    
    async def _copy_mcp_manager(self, project_path: Path):
        """å¤åˆ¶MCPç®¡ç†å™¨"""
        cooragent_root = get_project_root()
        mcp_manager_source = cooragent_root / "src" / "manager" / "mcp.py"
        mcp_manager_target = project_path / "src" / "manager" / "mcp.py"
        
        if mcp_manager_source.exists():
            shutil.copy2(mcp_manager_source, mcp_manager_target)
    
    async def _generate_mcp_config(self, project_path: Path, tools_used: List[str]):
        """ç”ŸæˆMCPé…ç½®æ–‡ä»¶"""
        
        mcp_config = {
            "mcpServers": {}
        }
        
        # åŸºç¡€æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼ˆå¤§å¤šæ•°é¡¹ç›®éƒ½éœ€è¦ï¼‰
        mcp_config["mcpServers"]["filesystem"] = {
            "command": "npx",
            "args": [
                "-y",
                "@modelcontextprotocol/server-filesystem",
                str(project_path / "store"),
                str(project_path / "static")
            ]
        }
        
        # GitHubç‰ˆæœ¬çš„MCPæœåŠ¡å™¨é…ç½®
        github_mcp_servers = {
            "AMAP": {
                "url": "https://mcp.amap.com/sse",
                "env": {
                    "AMAP_MAPS_API_KEY": "your_amap_maps_api_key"
                }
            },
            "excel": {
                "command": "npx",
                "args": ["--yes", "@negokaz/excel-mcp-server"],
                "env": {
                    "EXCEL_MCP_PAGING_CELLS_LIMIT": "4000"
                }
            },
            "word": {
                "command": "python",
                "args": [str(project_path / "src" / "tools" / "MCP-Doc" / "server.py")]
            },
            "image-downloader": {
                "command": "node",
                "args": [str(project_path / "src" / "tools" / "mcp-image-downloader" / "build" / "index.js")]
            },
            "variflight-mcp": {
                "type": "sse",
                "url": "your_modelscope_variflight_mcp_url"
            }
        }
        
        # å·¥å…·åˆ°MCPæœåŠ¡å™¨çš„æ˜ å°„ï¼ˆGitHubç‰ˆæœ¬ï¼‰
        tool_to_mcp_mapping = {
            # åœ°å›¾ç›¸å…³å·¥å…·
            "maps_direction_driving": "AMAP",
            "maps_direction_transit": "AMAP",
            "maps_direction_walking": "AMAP",
            "maps_distance": "AMAP",
            "maps_geo": "AMAP",
            "maps_regeocode": "AMAP",
            "maps_ip_location": "AMAP",
            "maps_around_search": "AMAP",
            "maps_search_detail": "AMAP",
            "maps_text_search": "AMAP",
            "amap_tool": "AMAP",
            
            # Excelå·¥å…·
            "excel_tool": "excel",
            
            # æ–‡æ¡£å·¥å…·
            "mcp_doc": "word",
            "document_processor": "word",
            
            # å›¾ç‰‡ä¸‹è½½å·¥å…·
            "mcp_image_downloader": "image-downloader",
            "image_downloader": "image-downloader",
            
            # èˆªç­å·¥å…·
            "searchFlightItineraries": "variflight-mcp",
            "flight_search": "variflight-mcp",
            "search_flights": "variflight-mcp"
        }
        
        # æ ¹æ®ä½¿ç”¨çš„å·¥å…·æ·»åŠ MCPæœåŠ¡å™¨
        for tool in tools_used:
            if tool in tool_to_mcp_mapping:
                mcp_server_name = tool_to_mcp_mapping[tool]
                if mcp_server_name in github_mcp_servers:
                    mcp_config["mcpServers"][mcp_server_name] = github_mcp_servers[mcp_server_name]
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_path = project_path / "config" / "mcp.json"
        async with aiofiles.open(config_path, "w", encoding="utf-8") as f:
            await f.write(json.dumps(mcp_config, indent=2, ensure_ascii=False))
    
    async def _copy_mcp_tools(self, project_path: Path, tools_used: List[str]):
        """å¤åˆ¶MCPå·¥å…·æœåŠ¡å™¨"""
        cooragent_root = get_project_root()
        tools_source_dir = cooragent_root / "src" / "tools"
        tools_target_dir = project_path / "src" / "tools"
        
        mcp_tools_mapping = {
            "mcp_doc": "MCP-Doc",
            "mcp_image_downloader": "mcp-image-downloader"
        }
        
        for tool in tools_used:
            if tool in mcp_tools_mapping:
                tool_dir = mcp_tools_mapping[tool]
                source_path = tools_source_dir / tool_dir
                target_path = tools_target_dir / tool_dir
                
                if source_path.exists():
                    shutil.copytree(source_path, target_path, dirs_exist_ok=True)
    
    async def _generate_mcp_setup_scripts(self, project_path: Path, tools_used: List[str]):
        """ç”ŸæˆMCPå®‰è£…è„šæœ¬"""
        
        setup_script = '''#!/bin/bash
# MCPå·¥å…·å®‰è£…è„šæœ¬

echo "æ­£åœ¨å®‰è£…MCPå·¥å…·ä¾èµ–..."

# å®‰è£…Node.js MCPå·¥å…·
if command -v npm &> /dev/null; then
    echo "å®‰è£…æ–‡ä»¶ç³»ç»ŸMCPæœåŠ¡å™¨..."
    npm install -g @modelcontextprotocol/server-filesystem
    
'''
        
        if "mcp_image_downloader" in tools_used:
            setup_script += '''    echo "æž„å»ºå›¾ç‰‡ä¸‹è½½å™¨MCPå·¥å…·..."
    cd src/tools/mcp-image-downloader
    npm install
    npm run build
    cd ../../../
    
'''
        
        setup_script += '''else
    echo "è­¦å‘Š: æœªæ‰¾åˆ°npmï¼Œè¯·æ‰‹åŠ¨å®‰è£…Node.jså’Œnpm"
fi

# å®‰è£…Python MCPå·¥å…·ä¾èµ–
if [ -f requirements.txt ]; then
    echo "å®‰è£…Pythonä¾èµ–..."
    pip install -r requirements.txt
fi

echo "MCPå·¥å…·å®‰è£…å®Œæˆï¼"
'''
        
        script_path = project_path / "setup_mcp.sh"
        async with aiofiles.open(script_path, "w", encoding="utf-8") as f:
            await f.write(setup_script)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        script_path.chmod(0o755)


class ProjectIntegrityValidator:
    """é¡¹ç›®å®Œæ•´æ€§éªŒè¯å™¨"""
    
    async def validate_project_integrity(self, project_path: Path, requirements: Dict[str, Any], progress_callback=None) -> Dict[str, Any]:
        """éªŒè¯ç”Ÿæˆé¡¹ç›®çš„å®Œæ•´æ€§"""
        
        if progress_callback:
            await progress_callback("éªŒè¯é¡¹ç›®å®Œæ•´æ€§...", 95, "é¡¹ç›®éªŒè¯", "æ£€æŸ¥ç›®å½•ç»“æž„ã€é…ç½®æ–‡ä»¶å’Œæ™ºèƒ½ä½“å®Œæ•´æ€§")
        
        validation_results = {
            "structure_check": await self._validate_directory_structure(project_path),
            "dependencies_check": await self._validate_dependencies(project_path),
            "configuration_check": await self._validate_configurations(project_path),
            "agents_check": await self._validate_agents_integrity(project_path),
            "runtime_check": await self._validate_runtime_requirements(project_path)
        }
        
        overall_status = all(result["status"] == "pass" for result in validation_results.values())
        
        return {
            "overall_status": "pass" if overall_status else "warning",
            "validation_results": validation_results,
            "recommendations": self._generate_recommendations(validation_results)
        }
    
    async def _validate_directory_structure(self, project_path: Path) -> Dict[str, Any]:
        """éªŒè¯ç›®å½•ç»“æž„"""
        required_dirs = [
            "src/interface", "src/workflow", "src/manager", "src/llm",
            "src/tools", "src/prompts", "src/utils", "src/service",
            "config", "store/agents", "store/prompts", "store/workflows", "static"
        ]
        
        missing_dirs = []
        for dir_path in required_dirs:
            if not (project_path / dir_path).exists():
                missing_dirs.append(dir_path)
        
        return {
            "status": "pass" if not missing_dirs else "fail",
            "missing_directories": missing_dirs,
            "total_required": len(required_dirs)
        }
    
    async def _validate_agents_integrity(self, project_path: Path) -> Dict[str, Any]:
        """éªŒè¯æ™ºèƒ½ä½“å®Œæ•´æ€§"""
        
        agents_dir = project_path / "store" / "agents"
        prompts_dir = project_path / "store" / "prompts"
        
        agent_files = list(agents_dir.glob("*.json"))
        prompt_files = list(prompts_dir.glob("*.md"))
        
        missing_prompts = []
        invalid_agents = []
        
        for agent_file in agent_files:
            try:
                # éªŒè¯JSONæ ¼å¼
                async with aiofiles.open(agent_file, "r", encoding="utf-8") as f:
                    agent_data = json.loads(await f.read())
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ["agent_name", "description", "llm_type", "selected_tools", "prompt"]
                missing_fields = [field for field in required_fields if field not in agent_data]
                
                if missing_fields:
                    invalid_agents.append({
                        "file": agent_file.name,
                        "missing_fields": missing_fields
                    })
                
                # æ£€æŸ¥å¯¹åº”çš„æç¤ºè¯æ–‡ä»¶
                prompt_file = prompts_dir / f"{agent_data['agent_name']}.md"
                if not prompt_file.exists():
                    missing_prompts.append(agent_data['agent_name'])
                
            except Exception as e:
                invalid_agents.append({
                    "file": agent_file.name,
                    "error": str(e)
                })
        
        status = "pass" if not missing_prompts and not invalid_agents else "fail"
        
        return {
            "status": status,
            "agent_count": len(agent_files),
            "prompt_count": len(prompt_files),
            "missing_prompts": missing_prompts,
            "invalid_agents": invalid_agents
        }
    
    async def _validate_dependencies(self, project_path: Path) -> Dict[str, Any]:
        """éªŒè¯ä¾èµ–æ–‡ä»¶"""
        required_files = ["requirements.txt", ".env.example", "main.py"]
        missing_files = []
        
        for file_name in required_files:
            if not (project_path / file_name).exists():
                missing_files.append(file_name)
        
        return {
            "status": "pass" if not missing_files else "fail",
            "missing_files": missing_files
        }
    
    async def _validate_configurations(self, project_path: Path) -> Dict[str, Any]:
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        config_files = ["config/workflow.json"]
        invalid_configs = []
        
        for config_file in config_files:
            config_path = project_path / config_file
            if config_path.exists():
                try:
                    async with aiofiles.open(config_path, "r", encoding="utf-8") as f:
                        json.loads(await f.read())
                except json.JSONDecodeError as e:
                    invalid_configs.append({
                        "file": config_file,
                        "error": str(e)
                    })
        
        return {
            "status": "pass" if not invalid_configs else "fail",
            "invalid_configs": invalid_configs
        }
    
    async def _validate_runtime_requirements(self, project_path: Path) -> Dict[str, Any]:
        """éªŒè¯è¿è¡Œæ—¶éœ€æ±‚"""
        issues = []
        
        # æ£€æŸ¥ä¸»åº”ç”¨æ–‡ä»¶
        main_py = project_path / "main.py"
        if not main_py.exists():
            issues.append("ç¼ºå°‘ä¸»åº”ç”¨å…¥å£æ–‡ä»¶ main.py")
        
        # æ£€æŸ¥å¯åŠ¨è„šæœ¬
        start_script = project_path / "start.sh"
        if not start_script.exists():
            issues.append("ç¼ºå°‘å¯åŠ¨è„šæœ¬ start.sh")
        
        return {
            "status": "pass" if not issues else "fail",
            "issues": issues
        }
    
    def _generate_recommendations(self, validation_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        for check_name, result in validation_results.items():
            if result["status"] == "fail":
                if check_name == "structure_check" and result.get("missing_directories"):
                    recommendations.append(f"åˆ›å»ºç¼ºå¤±çš„ç›®å½•: {', '.join(result['missing_directories'])}")
                elif check_name == "agents_check" and result.get("missing_prompts"):
                    recommendations.append(f"è¡¥å……ç¼ºå¤±çš„æç¤ºè¯æ–‡ä»¶: {', '.join(result['missing_prompts'])}")
                elif check_name == "dependencies_check" and result.get("missing_files"):
                    recommendations.append(f"æ·»åŠ ç¼ºå¤±çš„ä¾èµ–æ–‡ä»¶: {', '.join(result['missing_files'])}")
        
        return recommendations


class EnhancedCooragentProjectGenerator:
    """å¢žå¼ºçš„Cooragenté¡¹ç›®ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "generated_projects"):
        self.cooragent_root = get_project_root()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.component_analyzer = DynamicComponentAnalyzer()
        self.mcp_integrator = MCPEcosystemIntegrator()
        self.validator = ProjectIntegrityValidator()
        self.config_generator = ConfigGenerator()
    
    async def generate_project(self, user_input: str, user_id: str = None, progress_callback=None) -> Path:
        """
        å¢žå¼ºçš„é¡¹ç›®ç”Ÿæˆæµç¨‹
        
        Args:
            user_input: ç”¨æˆ·éœ€æ±‚æè¿°
            user_id: ç”¨æˆ·IDï¼Œç”¨äºŽéš”ç¦»ä¸åŒç”¨æˆ·çš„æ™ºèƒ½ä½“
            progress_callback: è¿›åº¦æ›´æ–°å›žè°ƒå‡½æ•°
            
        Returns:
            ç”Ÿæˆçš„åŽ‹ç¼©åŒ…è·¯å¾„
        """
        if user_id is None:
            user_id = f"gen_{int(time.time())}"
            
        logger.info(f"å¼€å§‹ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆå¢žå¼ºé¡¹ç›®ï¼Œéœ€æ±‚: {user_input[:100]}...")
        
        if progress_callback:
            await progress_callback(
                "åˆå§‹åŒ–å¢žå¼ºä»£ç ç”Ÿæˆå™¨...", 
                5, "åˆå§‹åŒ–", "è®¾ç½®Cooragentå¢žå¼ºç”ŸæˆçŽ¯å¢ƒå’Œç»„ä»¶"
            )
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šæ‰§è¡Œå®Œæ•´å·¥ä½œæµå¹¶ç­‰å¾…å®Œæˆ
            workflow_result = await self._execute_complete_workflow(user_input, user_id, progress_callback)
            
            # ç¬¬äºŒé˜¶æ®µï¼šä»Žstoreè¯»å–æ™ºèƒ½ä½“é…ç½®
            agents_config = await self._load_agents_from_store(user_id, progress_callback)
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šåŠ¨æ€åˆ†æžé¡¹ç›®éœ€æ±‚
            project_requirements = await self._analyze_dynamic_requirements(agents_config, progress_callback)
            
            # ç¬¬å››é˜¶æ®µï¼šç”Ÿæˆç‹¬ç«‹é¡¹ç›®
            project_path = await self._generate_independent_project(project_requirements, agents_config, progress_callback)
            
            # ç¬¬äº”é˜¶æ®µï¼šéªŒè¯é¡¹ç›®å®Œæ•´æ€§
            validation_result = await self.validator.validate_project_integrity(project_path, project_requirements, progress_callback)
            
            # ç¬¬å…­é˜¶æ®µï¼šåŽ‹ç¼©é¡¹ç›®
            if progress_callback:
                await progress_callback("åŽ‹ç¼©é¡¹ç›®æ–‡ä»¶...", 98, "é¡¹ç›®æ‰“åŒ…", "ç”Ÿæˆå¯ä¸‹è½½çš„å®Œæ•´åº”ç”¨åŒ…")
            
            zip_path = await self._compress_project(project_path)
            
            if progress_callback:
                await progress_callback(
                    f"ç”Ÿæˆå®Œæˆï¼éªŒè¯çŠ¶æ€: {validation_result['overall_status']}", 
                    100, "å®Œæˆ", 
                    f"é¡¹ç›®å·²æ‰“åŒ…ä¸º: {zip_path.name}"
                )
            
            logger.info(f"å¢žå¼ºé¡¹ç›®ç”Ÿæˆå®Œæˆ: {zip_path}")
            return zip_path
            
        except Exception as e:
            logger.error(f"å¢žå¼ºé¡¹ç›®ç”Ÿæˆå¤±è´¥: {e}")
            
            if progress_callback:
                await progress_callback(f"ç”Ÿæˆå¤±è´¥: {str(e)}", 0, "é”™è¯¯", f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {str(e)}")
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶ç”Ÿæˆçš„æ™ºèƒ½ä½“
            await self._cleanup_user_agents(user_id, progress_callback)
    
    async def _execute_complete_workflow(self, user_input: str, user_id: str, progress_callback=None) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµå¹¶ç­‰å¾…æ‰€æœ‰æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ"""
        
        if progress_callback:
            await progress_callback("å¯åŠ¨Cooragentå¤šæ™ºèƒ½ä½“åä½œåˆ†æž...", 10, "å·¥ä½œæµæ‰§è¡Œ", "åˆå§‹åŒ–åè°ƒå™¨ã€è§„åˆ’å™¨ã€æ™ºèƒ½ä½“å·¥åŽ‚")
        
        messages = [{"role": "user", "content": user_input}]
        final_result = {}
        events = []
        
        logger.info("å¼€å§‹æ‰§è¡Œå®Œæ•´å·¥ä½œæµ...")
        
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
        async for event_data in run_agent_workflow(
            user_id=user_id,
            task_type=TaskType.AGENT_WORKFLOW,
            user_input_messages=messages,
            debug=False,
            deep_thinking_mode=True,
            search_before_planning=True,
            workmode="launch"
        ):
            events.append(event_data)
            
            # æ›´æ–°è¿›åº¦
            if event_data.get("event") == "start_of_agent":
                agent_name = event_data.get("data", {}).get("agent_name")
                if progress_callback:
                    progress = min(15 + len(events), 25)
                    await progress_callback(
                        f"æ‰§è¡Œ {agent_name} æ™ºèƒ½ä½“...", 
                        progress, 
                        "å¤šæ™ºèƒ½ä½“åä½œ", 
                        f"å½“å‰æ‰§è¡Œ: {agent_name}"
                    )
            
            final_result = event_data
        
        # ç­‰å¾…æ™ºèƒ½ä½“å®Œå…¨åˆ›å»ºå’ŒæŒä¹…åŒ–
        if progress_callback:
            await progress_callback("ç­‰å¾…æ™ºèƒ½ä½“é…ç½®æŒä¹…åŒ–å®Œæˆ...", 30, "é…ç½®åŒæ­¥", "ç¡®ä¿æ‰€æœ‰æ™ºèƒ½ä½“é…ç½®å·²ä¿å­˜åˆ°storeç›®å½•")
        
        logger.info("å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œç­‰å¾…æ™ºèƒ½ä½“æŒä¹…åŒ–...")
        await asyncio.sleep(3)  # ç»™è¶³æ—¶é—´è®©æ™ºèƒ½ä½“å®Œå…¨åˆ›å»ºå’ŒæŒä¹…åŒ–
        
        return final_result
    
    async def _load_agents_from_store(self, user_id: str, progress_callback=None) -> Dict[str, Any]:
        """ä»Žstoreç›®å½•è¯»å–ç”¨æˆ·çš„æ™ºèƒ½ä½“é…ç½®"""
        
        if progress_callback:
            await progress_callback("ä»Žstoreç›®å½•åŠ è½½æ™ºèƒ½ä½“é…ç½®...", 35, "é…ç½®åŠ è½½", "è¯»å–æŒä¹…åŒ–çš„æ™ºèƒ½ä½“å’Œæç¤ºè¯æ–‡ä»¶")
        
        agents = []
        prompts = {}
        tools_used = set()
        
        # è¯»å–æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶
        agents_dir = get_project_root() / "store" / "agents"
        prompts_dir = get_project_root() / "store" / "prompts"
        
        logger.info(f"ðŸ” [æ™ºèƒ½ä½“åˆ†æž] å¼€å§‹ä»Ž {agents_dir} åŠ è½½æ™ºèƒ½ä½“é…ç½®...")
        logger.info(f"ðŸŽ¯ [æ™ºèƒ½ä½“åˆ†æž] ç›®æ ‡ç”¨æˆ·ID: {user_id}")
        
        # åˆ—å‡ºæ‰€æœ‰æ™ºèƒ½ä½“æ–‡ä»¶
        all_agent_files = list(agents_dir.glob("*.json"))
        logger.info(f"ðŸ“‚ [æ™ºèƒ½ä½“åˆ†æž] å‘çŽ° {len(all_agent_files)} ä¸ªæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶")
        
        # è¯¦ç»†åˆ†æžæ¯ä¸ªæ™ºèƒ½ä½“æ–‡ä»¶
        user_agents_found = []
        all_agents_info = []
        
        for agent_file in all_agent_files:
            try:
                async with aiofiles.open(agent_file, "r", encoding="utf-8") as f:
                    agent_data = json.loads(await f.read())
                
                file_user_id = agent_data.get("user_id", "æœªè®¾ç½®")
                agent_name = agent_data.get("agent_name", "æœªè®¾ç½®")
                agent_description = agent_data.get("agent_description", "æ— æè¿°")[:50]
                
                all_agents_info.append({
                    "file": agent_file.name,
                    "agent_name": agent_name,
                    "user_id": file_user_id,
                    "description": agent_description
                })
                
                logger.info(f"ðŸ“‹ [æ™ºèƒ½ä½“åˆ†æž] æ–‡ä»¶: {agent_file.name}")
                logger.info(f"   â”œâ”€ æ™ºèƒ½ä½“åç§°: {agent_name}")
                logger.info(f"   â”œâ”€ ç”¨æˆ·ID: {file_user_id}")
                logger.info(f"   â”œâ”€ æè¿°: {agent_description}")
                logger.info(f"   â””â”€ åŒ¹é…ç›®æ ‡ç”¨æˆ·: {'âœ… æ˜¯' if file_user_id == user_id else 'âŒ å¦'}")
                
                # æ™ºèƒ½åŒ¹é…ç”¨æˆ·æ™ºèƒ½ä½“
                is_match = False
                match_reason = ""
                
                # ç²¾ç¡®åŒ¹é…
                if file_user_id == user_id:
                    is_match = True
                    match_reason = "ç²¾ç¡®åŒ¹é…"
                # æ—…æ¸¸ç”¨æˆ·æ¨¡ç³ŠåŒ¹é…ï¼štravel_user_123456 åŒ¹é… travel_user
                elif user_id.startswith("travel_user_") and file_user_id == "travel_user":
                    is_match = True
                    match_reason = "æ—…æ¸¸ç”¨æˆ·æ¨¡ç³ŠåŒ¹é…"
                # æµ‹è¯•ç”¨æˆ·åŒ¹é…ï¼štravel_user_123456 åŒ¹é… travel_test  
                elif user_id.startswith("travel_user_") and file_user_id == "travel_test":
                    is_match = True
                    match_reason = "æµ‹è¯•ç”¨æˆ·åŒ¹é…"
                
                if is_match:
                    agent = Agent.model_validate(agent_data)
                    agents.append(agent)
                    user_agents_found.append(agent_name)
                    
                    logger.info(f"âœ… [æ™ºèƒ½ä½“åˆ†æž] æˆåŠŸåŠ è½½ç”¨æˆ·æ™ºèƒ½ä½“: {agent.agent_name} ({match_reason})")
                    
                    # æ”¶é›†ä½¿ç”¨çš„å·¥å…·
                    for tool in agent.selected_tools:
                        tools_used.add(tool.name)
                    
                    # è¯»å–å¯¹åº”çš„æç¤ºè¯æ–‡ä»¶
                    prompt_file = prompts_dir / f"{agent.agent_name}.md"
                    if prompt_file.exists():
                        async with aiofiles.open(prompt_file, "r", encoding="utf-8") as f:
                            prompts[agent.agent_name] = await f.read()
                    
            except Exception as e:
                logger.warning(f"âŒ [æ™ºèƒ½ä½“åˆ†æž] åŠ è½½æ™ºèƒ½ä½“æ–‡ä»¶å¤±è´¥ {agent_file}: {e}")
        
        # è¾“å‡ºå®Œæ•´çš„æ™ºèƒ½ä½“åˆ†æžæŠ¥å‘Š
        logger.info(f"ðŸ“Š [æ™ºèƒ½ä½“åˆ†æž] å®Œæ•´æ™ºèƒ½ä½“åˆ—è¡¨:")
        for i, info in enumerate(all_agents_info, 1):
            logger.info(f"   {i}. {info['agent_name']} (ç”¨æˆ·: {info['user_id']}) - {info['description']}")
        
        logger.info(f"ðŸŽ¯ [æ™ºèƒ½ä½“åˆ†æž] ç›®æ ‡ç”¨æˆ· '{user_id}' çš„æ™ºèƒ½ä½“:")
        if user_agents_found:
            for agent_name in user_agents_found:
                logger.info(f"   âœ… {agent_name}")
        else:
            logger.info(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„æ™ºèƒ½ä½“")
        
        # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·ç‰¹å®šçš„æ™ºèƒ½ä½“ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if not agents:
            logger.warning(f"âš ï¸ [æ™ºèƒ½ä½“åˆ†æž] æœªæ‰¾åˆ°ç”¨æˆ· {user_id} çš„ä¸“å±žæ™ºèƒ½ä½“ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            logger.warning(f"ðŸ’¡ [æ™ºèƒ½ä½“åˆ†æž] å¯èƒ½çš„åŽŸå› :")
            logger.warning(f"   1. ç”¨æˆ· {user_id} ä»Žæœªåˆ›å»ºè¿‡ä¸“å±žæ™ºèƒ½ä½“")
            logger.warning(f"   2. æ™ºèƒ½ä½“æ–‡ä»¶ä¸­çš„user_idå­—æ®µä¸Žå½“å‰ç”¨æˆ·IDä¸åŒ¹é…")
            logger.warning(f"   3. æ™ºèƒ½ä½“æ–‡ä»¶æŸåæˆ–æ ¼å¼é”™è¯¯")
            
            # æ·»åŠ ä¸€äº›é»˜è®¤æ™ºèƒ½ä½“
            default_agents = ["researcher", "coder", "reporter"]
            for agent_name in default_agents:
                if agent_name in agent_manager.available_agents:
                    agent = agent_manager.available_agents[agent_name]
                    # ä¿®æ”¹user_idä¸ºå½“å‰ç”¨æˆ·
                    agent_data = agent.model_dump()
                    agent_data["user_id"] = user_id
                    agent = Agent.model_validate(agent_data)
                    agents.append(agent)
                    
                    for tool in agent.selected_tools:
                        tools_used.add(tool.name)
        
        if progress_callback:
            await progress_callback(
                f"æˆåŠŸåŠ è½½ {len(agents)} ä¸ªæ™ºèƒ½ä½“é…ç½®", 
                40, 
                "é…ç½®åŠ è½½å®Œæˆ", 
                f"æ™ºèƒ½ä½“: {[a.agent_name for a in agents]}, å·¥å…·: {list(tools_used)}"
            )
        
        logger.info(f"æ™ºèƒ½ä½“é…ç½®åŠ è½½å®Œæˆ: {len(agents)} ä¸ªæ™ºèƒ½ä½“, {len(tools_used)} ä¸ªå·¥å…·")
        
        return {
            "agents": agents,
            "prompts": prompts,
            "tools_used": list(tools_used),
            "user_id": user_id
        }
    
    async def _analyze_dynamic_requirements(self, agents_config: Dict[str, Any], progress_callback=None) -> Dict[str, Any]:
        """åŠ¨æ€åˆ†æžé¡¹ç›®éœ€æ±‚"""
        
        if progress_callback:
            await progress_callback("åŠ¨æ€åˆ†æžé¡¹ç›®éœ€æ±‚...", 45, "éœ€æ±‚åˆ†æž", "æ ¹æ®æ™ºèƒ½ä½“é…ç½®åˆ†æžæ‰€éœ€ç»„ä»¶å’Œä¾èµ–")
        
        requirements = await self.component_analyzer.analyze_requirements(agents_config)
        
        logger.info(f"é¡¹ç›®éœ€æ±‚åˆ†æžå®Œæˆ: {len(requirements['core_components'])} ç±»æ ¸å¿ƒç»„ä»¶, {len(requirements['tool_components'])} ä¸ªå·¥å…·ç»„ä»¶")
        
        return requirements
    
    async def _generate_independent_project(self, requirements: Dict[str, Any], agents_config: Dict[str, Any], progress_callback=None) -> Path:
        """ç”Ÿæˆç‹¬ç«‹å¯è¿è¡Œçš„é¡¹ç›®"""
        
        project_name = f"cooragent_app_{int(time.time())}"
        project_path = self.output_dir / project_name
        
        # 1. åˆ›å»ºé¡¹ç›®ç»“æž„
        await self._create_enhanced_project_structure(project_path, requirements)
        
        # 2. å¤åˆ¶å’Œå®šåˆ¶æ ¸å¿ƒç»„ä»¶
        if progress_callback:
            await progress_callback("å¤åˆ¶Cooragentæ ¸å¿ƒç»„ä»¶...", 50, "é¡¹ç›®æž„å»º", "å¤åˆ¶æ™ºèƒ½ä½“ç®¡ç†ã€å·¥ä½œæµå¼•æ“Žç­‰æ ¸å¿ƒæ¨¡å—")
        
        await self._copy_and_customize_components(project_path, requirements)
        
        # 3. ç”Ÿæˆæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶
        if progress_callback:
            await progress_callback("ç”Ÿæˆæ™ºèƒ½ä½“é…ç½®...", 60, "æ™ºèƒ½ä½“é…ç½®", "åˆ›å»ºæ™ºèƒ½ä½“JSONé…ç½®å’Œæç¤ºè¯æ–‡ä»¶")
        
        await self._generate_agent_configs(project_path, agents_config)
        
        # 4. é›†æˆMCPç”Ÿæ€ç³»ç»Ÿ
        await self.mcp_integrator.integrate_mcp_ecosystem(project_path, agents_config["tools_used"], progress_callback)
        
        # 5. ç”Ÿæˆç‹¬ç«‹çš„ä¸»åº”ç”¨
        if progress_callback:
            await progress_callback("ç”Ÿæˆä¸»åº”ç”¨å…¥å£...", 75, "åº”ç”¨ç”Ÿæˆ", "åˆ›å»ºFastAPIåº”ç”¨å’Œè·¯ç”±é…ç½®")
        
        await self._generate_independent_main_app(project_path, requirements, agents_config)
        
        # 6. ç”ŸæˆçŽ¯å¢ƒé…ç½®å’Œä¾èµ–æ–‡ä»¶
        if progress_callback:
            await progress_callback("ç”ŸæˆçŽ¯å¢ƒé…ç½®...", 80, "çŽ¯å¢ƒé…ç½®", "åˆ›å»ºçŽ¯å¢ƒå˜é‡ã€ä¾èµ–æ–‡ä»¶å’Œé…ç½®æ¨¡æ¿")
        
        await self._generate_environment_configs(project_path, requirements, agents_config)
        await self._generate_requirements(project_path, agents_config)
        
        # 7. ç”Ÿæˆéƒ¨ç½²æ–‡ä»¶
        if progress_callback:
            await progress_callback("ç”Ÿæˆéƒ¨ç½²æ–‡ä»¶...", 85, "éƒ¨ç½²é…ç½®", "åˆ›å»ºDockerã€docker-composeå’Œå¯åŠ¨è„šæœ¬")
        
        await self._generate_deployment_configs(project_path, requirements, agents_config)
        
        # 8. ç”Ÿæˆç¼ºå¤±çš„ç³»ç»Ÿæ–‡ä»¶
        if progress_callback:
            await progress_callback("ç”Ÿæˆç¼ºå¤±çš„ç³»ç»Ÿæ–‡ä»¶...", 88, "ç³»ç»Ÿæ–‡ä»¶", "åˆ›å»ºchinese_names.pyã€coor_task.pyç­‰è‡ªåˆ›å»ºæ–‡ä»¶")
        
        await self._generate_missing_system_files(project_path, agents_config)
        
        # 9. ç”Ÿæˆæ–‡æ¡£
        if progress_callback:
            await progress_callback("ç”Ÿæˆé¡¹ç›®æ–‡æ¡£...", 90, "æ–‡æ¡£ç”Ÿæˆ", "åˆ›å»ºREADMEã€APIæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—")
        
        await self._generate_comprehensive_documentation(project_path, requirements, agents_config)
        
        return project_path
    
    async def _create_enhanced_project_structure(self, project_path: Path, requirements: Dict[str, Any]):
        """åˆ›å»ºå¢žå¼ºçš„é¡¹ç›®ç›®å½•ç»“æž„"""
        dirs = [
            "src/interface",
            "src/workflow", 
            "src/manager",
            "src/llm",
            "src/tools",
            "src/prompts",
            "src/utils",
            "src/service",
            "config",
            "store/agents",
            "store/prompts", 
            "store/workflows",
            "static",
            "logs"
        ]
        
        for dir_path in dirs:
            (project_path / dir_path).mkdir(parents=True, exist_ok=True)
    
    async def _copy_and_customize_components(self, project_path: Path, requirements: Dict[str, Any]):
        """å¤åˆ¶å’Œå®šåˆ¶åŒ–Cooragentæ ¸å¿ƒç»„ä»¶"""
        logger.info("å¤åˆ¶Cooragentæ ¸å¿ƒç»„ä»¶...")
        
        src_path = project_path / "src"
        
        # å¤åˆ¶æ ¸å¿ƒç»„ä»¶
        for component_type, files in requirements["core_components"].items():
            target_dir = src_path / component_type
            source_dir = self.cooragent_root / "src" / component_type
            
            for file in files:
                source_file = source_dir / file
                if source_file.exists():
                    target_file = target_dir / file
                    if source_file.is_file():
                        shutil.copy2(source_file, target_file)
                    elif source_file.is_dir():
                        shutil.copytree(source_file, target_file, dirs_exist_ok=True)
                
                # ç¡®ä¿æœ‰__init__.pyæ–‡ä»¶
                init_file = target_dir / "__init__.py"
                if not init_file.exists():
                    init_file.touch()
        
        # å¤åˆ¶å·¥å…·ç»„ä»¶
        for tool_name, files in requirements["tool_components"].items():
            tools_source_dir = self.cooragent_root / "src" / "tools"
            tools_target_dir = src_path / "tools"
            
            # ç¡®ä¿toolsç›®å½•å­˜åœ¨
            tools_target_dir.mkdir(parents=True, exist_ok=True)
            
            for file in files:
                source_file = tools_source_dir / file
                if source_file.exists():
                    if source_file.is_file():
                        target_file = tools_target_dir / file
                        shutil.copy2(source_file, target_file)
                    elif source_file.is_dir():
                        target_dir = tools_target_dir / file
                        shutil.copytree(source_file, target_dir, dirs_exist_ok=True)
                else:
                    logger.warning(f"å·¥å…·æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
            
            # ç¡®ä¿toolsç›®å½•æœ‰__init__.pyæ–‡ä»¶
            tools_init_file = src_path / "tools" / "__init__.py"
            if not tools_init_file.exists():
                tools_init_file.touch()
        
        # å¤åˆ¶MCPç®¡ç†å™¨
        mcp_manager_source = self.cooragent_root / "src" / "manager" / "mcp.py"
        mcp_manager_target = project_path / "src" / "manager" / "mcp.py"
        if mcp_manager_source.exists():
            shutil.copy2(mcp_manager_source, mcp_manager_target)
        
        # å¤åˆ¶MCPå·¥å…·æœåŠ¡å™¨
        for tool_name, files in requirements["mcp_components"].items():
            tools_source_dir = self.cooragent_root / "src" / "tools"
            tools_target_dir = src_path / "tools"
            
            # ç¡®ä¿toolsç›®å½•å­˜åœ¨
            tools_target_dir.mkdir(parents=True, exist_ok=True)
            
            for file in files:
                source_file = tools_source_dir / file
                if source_file.exists():
                    if source_file.is_file():
                        target_file = tools_target_dir / file
                        shutil.copy2(source_file, target_file)
                    elif source_file.is_dir():
                        target_dir = tools_target_dir / file
                        shutil.copytree(source_file, target_dir, dirs_exist_ok=True)
                else:
                    logger.warning(f"MCPå·¥å…·æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
            
            # ç¡®ä¿toolsç›®å½•æœ‰__init__.pyæ–‡ä»¶
            tools_init_file = src_path / "tools" / "__init__.py"
            if not tools_init_file.exists():
                tools_init_file.touch()
    
    async def _generate_agent_configs(self, project_path: Path, agents_config: Dict[str, Any]):
        """ç”Ÿæˆæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶"""
        agents_dir = project_path / "store" / "agents"
        prompts_dir = project_path / "store" / "prompts"
        
        for agent in agents_config["agents"]:
            agent_data = agent.model_dump()
            agent_data["user_id"] = agents_config["user_id"]
            
            agent_file = agents_dir / f"{agent_data['agent_name']}.json"
            async with aiofiles.open(agent_file, "w", encoding="utf-8") as f:
                await f.write(json.dumps(agent_data, indent=2, ensure_ascii=False))
            
            prompt_file = prompts_dir / f"{agent_data['agent_name']}.md"
            if agent_data["prompt"]:
                async with aiofiles.open(prompt_file, "w", encoding="utf-8") as f:
                    await f.write(agent_data["prompt"])
            else:
                prompt_file.touch() # ç¡®ä¿æç¤ºè¯æ–‡ä»¶å­˜åœ¨
    
    async def _generate_environment_configs(self, project_path: Path, requirements: Dict[str, Any], agents_config: Dict[str, Any]):
        """ç”ŸæˆçŽ¯å¢ƒé…ç½®æ–‡ä»¶"""
        env_content = '''# ==========================================
# Cooragent å¤šæ™ºèƒ½ä½“åº”ç”¨çŽ¯å¢ƒé…ç½®
# åŸºäºŽåŽ†å²æ–‡æ¡£éœ€æ±‚çš„å®Œæ•´é…ç½®
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º.envå¹¶å¡«å…¥å®žé™…å€¼
# ==========================================

# === LLMæ¨¡åž‹é…ç½® (åŸºäºŽåŽ†å²æ–‡æ¡£è¦æ±‚) ===
# æŽ¨ç†æ¨¡åž‹é…ç½®
REASONING_API_KEY=your_reasoning_api_key_here
REASONING_BASE_URL=https://api.openai.com/v1
REASONING_MODEL=o1-preview

# åŸºç¡€æ¨¡åž‹é…ç½®
BASIC_API_KEY=your_basic_api_key_here
BASIC_BASE_URL=https://api.openai.com/v1
BASIC_MODEL=gpt-4

# ä»£ç æ¨¡åž‹é…ç½®
CODE_API_KEY=your_code_api_key_here
CODE_BASE_URL=https://api.deepseek.com/v1
CODE_MODEL=deepseek-chat

# è§†è§‰æ¨¡åž‹é…ç½®
VL_API_KEY=your_vl_api_key_here
VL_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
VL_MODEL=qwen2.5-vl-72b-instruct

# === å·¥ä½œæµé…ç½® ===
MAX_STEPS=25
MCP_AGENT=true
USE_BROWSER=false

# === å·¥å…·APIå¯†é’¥ (æ ¹æ®ä½¿ç”¨çš„å·¥å…·é…ç½®) ===
TAVILY_API_KEY=your_tavily_api_key_here
JINA_API_KEY=your_jina_api_key_here'''

        # æ ¹æ®ä½¿ç”¨çš„å·¥å…·æ·»åŠ ç›¸åº”çš„APIé…ç½®
        for tool in agents_config["tools_used"]:
            if tool in self.component_analyzer.tool_dependencies:
                tool_deps = self.component_analyzer.tool_dependencies[tool]
                for dep in tool_deps:
                    if dep.startswith("mcp_"):
                        env_content += f'''
{dep.upper()}_API_KEY=your_{dep.replace("_", "").replace("-", "")}_api_key_here'''
            elif tool.startswith("mcp_"):
                env_content += f'''
{tool.upper()}_API_KEY=your_{tool.replace("_", "").replace("-", "")}_api_key_here'''
        
        env_content += '''

# === äº‘æœåŠ¡é…ç½® ===
# é˜¿é‡Œäº‘DashScope
DASHSCOPE_API_KEY=your_dashscope_api_key_here

# === åº”ç”¨é…ç½® ===
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG=false
APP_ENV=production
LOG_LEVEL=INFO
USR_AGENT=cooragent_generated_app

# === å®‰å…¨é…ç½® ===
SECRET_KEY=your_secret_key_here
ANONYMIZED_TELEMETRY=false

# === æ•°æ®åº“é…ç½® (å¯é€‰) ===
# DATABASE_URL=sqlite:///./data/app.db

# === ç¼“å­˜é…ç½® (å¯é€‰) ===
# REDIS_URL=redis://localhost:6379/0

# === ç›‘æŽ§é…ç½® (å¯é€‰) ===
# SENTRY_DSN=your_sentry_dsn_here
'''
        
        async with aiofiles.open(project_path / ".env.example", "w", encoding="utf-8") as f:
            await f.write(env_content)
    
    async def _generate_missing_system_files(self, project_path: Path, agents_config: Dict[str, Any]):
        """ç”ŸæˆåŽ†å²æ–‡æ¡£ä¸­æåˆ°çš„ç¼ºå¤±æ–‡ä»¶"""
        
        # 1. ç”Ÿæˆ src/utils/chinese_names.py
        chinese_names_content = '''"""ä¸­æ–‡åç§°å’Œæ—¥å¿—å·¥å…·æ¨¡å—"""
import json
from datetime import datetime
from typing import Dict, Any

def generate_chinese_log(log_type: str, message: str, **kwargs) -> Dict[str, Any]:
    """ç”Ÿæˆä¸­æ–‡æ—¥å¿—æ¶ˆæ¯"""
    return {
        "timestamp": datetime.now().isoformat(),
        "type": log_type,
        "data": {
            "message": message,
            **kwargs
        }
    }

def get_agent_chinese_name(agent_name: str) -> str:
    """èŽ·å–æ™ºèƒ½ä½“çš„ä¸­æ–‡åç§°"""
    chinese_names = {
        "coordinator": "åè°ƒå‘˜",
        "planner": "è§„åˆ’å¸ˆ", 
        "researcher": "ç ”ç©¶å‘˜",
        "coder": "ç¨‹åºå‘˜",
        "reporter": "æŠ¥å‘Šå‘˜",
        "browser": "æµè§ˆå™¨æ“ä½œå‘˜",
        "agent_factory": "æ™ºèƒ½ä½“å·¥åŽ‚",
        "publisher": "å‘å¸ƒå‘˜"
    }
    return chinese_names.get(agent_name, agent_name)

def format_agent_progress_log(agent_name: str, progress: str) -> str:
    """æ ¼å¼åŒ–æ™ºèƒ½ä½“è¿›åº¦æ—¥å¿—"""
    return f"[{get_agent_chinese_name(agent_name)}] {progress}"

def format_code_generation_log(stage: str, progress: int, details: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–ä»£ç ç”Ÿæˆæ—¥å¿—"""
    return f"{stage} è¿›åº¦: {progress}% - {details}"

def format_download_log(action: str, details: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–ä¸‹è½½æ—¥å¿—"""
    return f"ä¸‹è½½{action}: {details}"

def get_execution_status_chinese(status: str) -> str:
    """èŽ·å–æ‰§è¡ŒçŠ¶æ€çš„ä¸­æ–‡æè¿°"""
    status_map = {
        "pending": "ç­‰å¾…ä¸­",
        "processing": "å¤„ç†ä¸­", 
        "completed": "å·²å®Œæˆ",
        "failed": "å¤±è´¥"
    }
    return status_map.get(status, status)
'''
        
        # 2. ç”Ÿæˆ src/workflow/coor_task.py
        coor_task_content = '''"""åè°ƒä»»åŠ¡å·¥ä½œæµæž„å»ºæ¨¡å—"""
import logging
import time
from typing import Dict, Any, List
from langchain.schema import BaseMessage
from langgraph.types import Command
from src.interface.agent import State
from src.workflow.graph import AgentWorkflow

logger = logging.getLogger(__name__)

async def coordinator_node(state: State) -> Command:
    """åè°ƒå‘˜èŠ‚ç‚¹ - æ™ºèƒ½åˆ†ç±»ç”¨æˆ·è¯·æ±‚"""
    messages = state.get("messages", [])
    if not messages:
        return Command(goto="__end__", update={"messages": []})
    
    # åŸºç¡€åè°ƒé€»è¾‘
    user_input = messages[-1].content if messages else ""
    
    # ç®€å•çš„ä»»åŠ¡åˆ†ç±»
    if len(user_input.split()) > 20:  # å¤æ‚ä»»åŠ¡
        return Command(goto="planner", update={"task_type": "complex"})
    else:  # ç®€å•ä»»åŠ¡  
        return Command(goto="agent_proxy", update={"task_type": "simple"})

def build_graph() -> AgentWorkflow:
    """æž„å»ºåè°ƒä»»åŠ¡å·¥ä½œæµå›¾"""
    workflow = AgentWorkflow()
    workflow.add_node("coordinator", coordinator_node)
    workflow.set_start("coordinator")
    return workflow.compile()
'''
        
        # 3. ç”Ÿæˆ src/workflow/agent_factory.py
        agent_factory_content = '''"""æ™ºèƒ½ä½“å·¥åŽ‚å·¥ä½œæµæž„å»ºæ¨¡å—"""
import logging
import time
from typing import Dict, Any
from langgraph.types import Command
from src.interface.agent import State, Agent
from src.workflow.graph import AgentWorkflow

logger = logging.getLogger(__name__)

async def agent_factory_node(state: State) -> Command:
    """æ™ºèƒ½ä½“å·¥åŽ‚èŠ‚ç‚¹ - åŠ¨æ€åˆ›å»ºæ™ºèƒ½ä½“"""
    messages = state.get("messages", [])
    task_requirements = state.get("task_requirements", {})
    
    # åŸºç¡€æ™ºèƒ½ä½“åˆ›å»ºé€»è¾‘
    new_agent = {
        "agent_name": f"dynamic_agent_{int(time.time())}",
        "description": "åŠ¨æ€åˆ›å»ºçš„æ™ºèƒ½ä½“",
        "llm_type": "basic",
        "selected_tools": [],
        "prompt": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å®Œæˆä»»åŠ¡ã€‚"
    }
    
    return Command(
        goto="__end__", 
        update={
            "created_agent": new_agent,
            "messages": messages
        }
    )

def agent_factory_graph() -> AgentWorkflow:
    """æž„å»ºæ™ºèƒ½ä½“å·¥åŽ‚å·¥ä½œæµå›¾"""
    workflow = AgentWorkflow()
    workflow.add_node("agent_factory", agent_factory_node)
    workflow.set_start("agent_factory")
    return workflow.compile()
'''
        
        # å†™å…¥æ–‡ä»¶
        utils_dir = project_path / "src" / "utils"
        workflow_dir = project_path / "src" / "workflow"
        
        async with aiofiles.open(utils_dir / "chinese_names.py", "w", encoding="utf-8") as f:
            await f.write(chinese_names_content)
            
        async with aiofiles.open(workflow_dir / "coor_task.py", "w", encoding="utf-8") as f:
            await f.write(coor_task_content)
            
        async with aiofiles.open(workflow_dir / "agent_factory.py", "w", encoding="utf-8") as f:
            await f.write(agent_factory_content)
        
        logger.info("ç”Ÿæˆäº†3ä¸ªç¼ºå¤±çš„ç³»ç»Ÿæ–‡ä»¶: chinese_names.py, coor_task.py, agent_factory.py")
    
    async def _generate_requirements(self, project_path: Path, agents_config: Dict[str, Any]):
        """ç”Ÿæˆå®Œæ•´çš„requirements.txtï¼ŒåŒ…å«æ‰€æœ‰åŽ†å²é—®é¢˜ä¸­çš„ä¾èµ–"""
        # åŸºç¡€ä¾èµ–
        base_requirements = [
            "fastapi>=0.104.0",
            "uvicorn>=0.24.0",
            "pydantic>=2.5.0",
            "python-dotenv>=1.0.0",
            "aiofiles>=23.2.1",
            "httpx>=0.25.0",
            "python-multipart>=0.0.6",
            "langchain>=0.1.0",
            "langchain-core>=0.1.0",
            "rich>=13.0.0"
        ]
        
        # LangGraphå·¥ä½œæµæ¡†æž¶ (å…³é”®ä¾èµ–)
        langgraph_requirements = [
            "langgraph>=0.5.4",
            "langgraph-checkpoint>=2.1.1",
            "langgraph-prebuilt>=0.5.2",
            "langgraph-sdk>=0.1.74"
        ]
        
        # MCPç”Ÿæ€ç³»ç»Ÿ (å…³é”®ä¾èµ–)
        mcp_requirements = [
            "langchain-mcp-adapters>=0.1.9",
            "mcp>=1.12.2",
            "httpx-sse>=0.4.1",
            "jsonschema>=4.25.0",
            "pydantic-settings>=2.10.1",
            "sse-starlette>=2.4.1"
        ]
        
        # LangChainç”Ÿæ€æ‰©å±•
        langchain_extended = [
            "langchain-community>=0.3.27",
            "langchain-experimental>=0.3.4",
            "langchain-openai>=0.2.0"
        ]
        
        # ç½‘é¡µå¤„ç†å’Œçˆ¬å–
        web_processing = [
            "beautifulsoup4>=4.13.4",
            "lxml>=6.0.0",
            "markdownify>=1.1.0",
            "readabilipy>=0.3.0",
            "html5lib>=1.1",
            "requests>=2.31.0"
        ]
        
        # æœç´¢å’Œè‡ªåŠ¨åŒ–å·¥å…·
        automation_tools = [
            "tavily-python>=0.7.10",
            "playwright>=1.54.0",
            "selenium>=4.34.2",
            "pyee>=13.0.0"
        ]
        
        # äº‘æœåŠ¡é›†æˆ
        cloud_services = [
            "dashscope>=1.19.0"
        ]
        
        # AIå’ŒMLå·¥å…·
        ai_tools = [
            "tiktoken>=0.9.0",
            "numpy>=2.3.2"
        ]
        
        # å¼‚æ­¥å’Œç½‘ç»œæ”¯æŒ
        async_network = [
            "aiohttp>=3.12.14",
            "websocket-client>=1.8.0",
            "trio>=0.30.0",
            "trio-websocket>=0.12.2"
        ]
        
        # ç³»ç»Ÿå’Œå·¥å…·
        system_tools = [
            "distro>=1.9.0",
            "psutil>=5.9.0"
        ]
        
        # å·¥å…·ç‰¹å®šä¾èµ–
        tool_specific_deps = {
            "tavily_tool": ["tavily-python>=0.7.10"],
            "python_repl_tool": ["jupyter>=1.0.0", "ipython>=8.0.0"],
            "crawl_tool": ["beautifulsoup4>=4.13.4", "requests>=2.31.0", "lxml>=6.0.0"],
            "browser_tool": ["playwright>=1.54.0", "selenium>=4.34.2"],
            "excel_tool": ["openpyxl>=3.1.0", "pandas>=2.0.0"],
            "gmail_tool": ["google-api-python-client>=2.100.0"],
            "slack_tool": ["slack-sdk>=3.21.0"],
            "video_tool": ["opencv-python>=4.8.0"],
            "mcp_doc": ["python-docx>=1.1.0"],
            "web_preview_tool": ["jinja2>=3.1.0"]
        }
        
        # åˆå¹¶æ‰€æœ‰ä¾èµ–
        all_requirements = []
        all_requirements.extend(base_requirements)
        all_requirements.extend(langgraph_requirements)
        all_requirements.extend(mcp_requirements)
        all_requirements.extend(langchain_extended)
        all_requirements.extend(web_processing)
        all_requirements.extend(automation_tools)
        all_requirements.extend(cloud_services)
        all_requirements.extend(ai_tools)
        all_requirements.extend(async_network)
        all_requirements.extend(system_tools)
        
        # æ·»åŠ å·¥å…·ç‰¹å®šä¾èµ–
        for tool in agents_config["tools_used"]:
            if tool in tool_specific_deps:
                all_requirements.extend(tool_specific_deps[tool])
        
        # åŽ»é‡å¹¶æŽ’åº
        final_requirements = sorted(list(set(all_requirements)))
        
        async with aiofiles.open(project_path / "requirements.txt", "w", encoding="utf-8") as f:
            await f.write("\n".join(final_requirements))
        
        logger.info(f"ç”Ÿæˆäº†åŒ…å« {len(final_requirements)} ä¸ªä¾èµ–åŒ…çš„ requirements.txt")
    
    async def _generate_independent_main_app(self, project_path: Path, requirements: Dict[str, Any], agents_config: Dict[str, Any]):
        """ç”Ÿæˆç‹¬ç«‹çš„ä¸»åº”ç”¨å…¥å£æ–‡ä»¶"""
        from .template_renderer import TemplateRenderer
        
        renderer = TemplateRenderer()
        main_content = await renderer.render_main_app(agents_config)
        
        async with aiofiles.open(project_path / "main.py", "w", encoding="utf-8") as f:
            await f.write(main_content)
    
    async def _generate_deployment_configs(self, project_path: Path, requirements: Dict[str, Any], agents_config: Dict[str, Any]):
        """ç”Ÿæˆéƒ¨ç½²æ–‡ä»¶"""
        from .template_renderer import TemplateRenderer
        
        renderer = TemplateRenderer()
        
        # ç”ŸæˆDockerfile
        dockerfile_content = await renderer.render_dockerfile(requirements)
        async with aiofiles.open(project_path / "Dockerfile", "w", encoding="utf-8") as f:
            await f.write(dockerfile_content)
        
        # ç”Ÿæˆdocker-compose.yml
        compose_content = await renderer.render_docker_compose(requirements)
        async with aiofiles.open(project_path / "docker-compose.yml", "w", encoding="utf-8") as f:
            await f.write(compose_content)
    
    async def _generate_comprehensive_documentation(self, project_path: Path, requirements: Dict[str, Any], agents_config: Dict[str, Any]):
        """ç”Ÿæˆé¡¹ç›®æ–‡æ¡£"""
        from .template_renderer import TemplateRenderer
        
        renderer = TemplateRenderer()
        readme_content = await renderer.render_readme(agents_config)
        
        async with aiofiles.open(project_path / "README.md", "w", encoding="utf-8") as f:
            await f.write(readme_content)
    
    async def _compress_project(self, project_path: Path) -> Path:
        """åŽ‹ç¼©é¡¹ç›®ä¸ºzipæ–‡ä»¶"""
        zip_path = project_path.with_suffix('.zip')
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in project_path.rglob('*'):
                if file_path.is_file():
                    # è®¡ç®—ç›¸å¯¹è·¯å¾„
                    arcname = file_path.relative_to(project_path.parent)
                    zipf.write(file_path, arcname)
        
        # åˆ é™¤åŽŸç›®å½•ï¼ˆå¯é€‰ï¼‰
        shutil.rmtree(project_path)
        
        logger.info(f"é¡¹ç›®å·²åŽ‹ç¼©ä¸º: {zip_path}")
        return zip_path
    
    async def _cleanup_user_agents(self, user_id: str, progress_callback=None):
        """æ¸…ç†ä¸´æ—¶ç”Ÿæˆçš„ç”¨æˆ·æ™ºèƒ½ä½“"""
        try:
            if progress_callback:
                await progress_callback("æ¸…ç†ä¸´æ—¶æ–‡ä»¶...", 99, "æ¸…ç†", "æ¸…ç†ä¸´æ—¶ç”Ÿæˆçš„æ™ºèƒ½ä½“é…ç½®")
            
            # ä»Žè¿è¡Œæ—¶ç®¡ç†å™¨æ¸…ç†
            agents_to_remove = []
            for agent_name, agent in agent_manager.available_agents.items():
                if hasattr(agent, 'user_id') and agent.user_id == user_id:
                    agents_to_remove.append(agent_name)
            
            for agent_name in agents_to_remove:
                if agent_name in agent_manager.available_agents:
                    del agent_manager.available_agents[agent_name]
            
            logger.info(f"æ¸…ç†å®Œæˆï¼Œç§»é™¤äº† {len(agents_to_remove)} ä¸ªä¸´æ—¶æ™ºèƒ½ä½“")
            
        except Exception as e:
            logger.warning(f"æ¸…ç†ç”¨æˆ·æ™ºèƒ½ä½“æ—¶å‡ºé”™: {e}")


# ä¸ºäº†å‘åŽå…¼å®¹ï¼Œä¿ç•™åŽŸæ¥çš„ç±»åä½œä¸ºåˆ«å
CooragentProjectGenerator = EnhancedCooragentProjectGenerator 