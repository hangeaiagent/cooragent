import logging
import json
from copy import deepcopy
from langgraph.types import Command
from typing import Literal
from datetime import datetime
from src.interface.agent import COORDINATOR, PLANNER, PUBLISHER, AGENT_FACTORY
from src.llm.llm import get_llm_by_type
from src.llm.agents import AGENT_LLM_MAP
from src.prompts.template import apply_prompt_template
from src.tools.search import tavily_tool
from src.interface.agent import State, Router
from src.manager import agent_manager
from src.prompts.template import apply_prompt
from langgraph.prebuilt import create_react_agent
from src.workflow.graph import AgentWorkflow
from src.service.env import MAX_STEPS
from src.workflow.cache import workflow_cache as cache
from src.utils.content_process import clean_response_tags
from src.interface.serializer import AgentBuilder
from src.utils.chinese_names import generate_chinese_log, format_agent_progress_log, get_agent_chinese_name
import asyncio

# ğŸ”„ æ–°å¢ï¼šå¯¼å…¥æ—…æ¸¸è§„åˆ’å™¨
from src.workflow.travel_planner import travel_planner_node


logger = logging.getLogger(__name__)


async def agent_factory_node(state: State) -> Command[Literal["publisher", "__end__"]]:
    """Node for the create agent agent that creates a new agent."""
    logger.info("Agent Factory Start to work in %s workmode", state["workflow_mode"])
    
    # æ™ºèƒ½ä½“å·¥å‚å¯åŠ¨æ—¥å¿—
    factory_start_log = generate_chinese_log(
        "agent_factory_start",
        "ğŸ­ æ™ºèƒ½ä½“å·¥å‚å¯åŠ¨ï¼Œå¼€å§‹åˆ†ææ™ºèƒ½ä½“åˆ›å»ºéœ€æ±‚",
        workflow_mode=state["workflow_mode"],
        user_id=state.get("user_id", "unknown"),
        workflow_id=state.get("workflow_id", "unknown")
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {factory_start_log['data']['message']}")

    goto = "publisher"
    tools = []

    if state["workflow_mode"] == "launch":
        # æ¢å¤ç³»ç»ŸèŠ‚ç‚¹çŠ¶æ€
        cache.restore_system_node(state["workflow_id"], AGENT_FACTORY, state["user_id"])
        
        # åº”ç”¨æ™ºèƒ½ä½“å·¥å‚æç¤ºè¯æ¨¡æ¿
        factory_prompt_log = generate_chinese_log(
            "agent_factory_prompt",
            "ğŸ“‹ æ­£åœ¨åº”ç”¨æ™ºèƒ½ä½“å·¥å‚æç¤ºè¯æ¨¡æ¿ï¼Œå‡†å¤‡è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½ä½“é…ç½®",
            prompt_template="agent_factory",
            llm_type=AGENT_LLM_MAP["agent_factory"]
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {factory_prompt_log['data']['message']}")
        
        messages = apply_prompt_template("agent_factory", state)
        
        # è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½ä½“è§„æ ¼
        llm_call_log = generate_chinese_log(
            "agent_factory_llm_call",
            "ğŸ¤– æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½ä½“è§„æ ¼ï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºç¡®ä¿é…ç½®å®Œæ•´æ€§",
            structured_output_type="AgentBuilder",
            reasoning_mode=True
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {llm_call_log['data']['message']}")
        
        agent_spec = await (
            get_llm_by_type(AGENT_LLM_MAP["agent_factory"])
            .with_structured_output(AgentBuilder)
            .ainvoke(messages)
        )
        
        # æ™ºèƒ½ä½“è§„æ ¼ç”Ÿæˆå®Œæˆæ—¥å¿—
        spec_generated_log = generate_chinese_log(
            "agent_spec_generated",
            f"âœ… æ™ºèƒ½ä½“è§„æ ¼ç”Ÿæˆå®Œæˆ: {agent_spec['agent_name']}",
            agent_name=agent_spec["agent_name"],
            agent_description=agent_spec["agent_description"],
            llm_type=agent_spec["llm_type"],
            selected_tools_count=len(agent_spec["selected_tools"]),
            selected_tools=[tool["name"] for tool in agent_spec["selected_tools"]]
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {spec_generated_log['data']['message']}")

        # å·¥å…·é€‰æ‹©å’ŒéªŒè¯
        tool_selection_log = generate_chinese_log(
            "tool_selection_start", 
            f"ğŸ› ï¸ å¼€å§‹ä¸ºæ™ºèƒ½ä½“ {agent_spec['agent_name']} é€‰æ‹©å’ŒéªŒè¯å·¥å…·",
            agent_name=agent_spec["agent_name"],
            requested_tools=[tool["name"] for tool in agent_spec["selected_tools"]],
            available_tools_count=len(agent_manager.available_tools)
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {tool_selection_log['data']['message']}")

        validated_tools = []
        failed_tools = []

        for tool in agent_spec["selected_tools"]:
            if agent_manager.available_tools.get(tool["name"]):
                tools.append(agent_manager.available_tools[tool["name"]])
                validated_tools.append(tool["name"])
                
                # å·¥å…·éªŒè¯æˆåŠŸæ—¥å¿—
                tool_valid_log = generate_chinese_log(
                    "tool_validated",
                    f"âœ… å·¥å…·éªŒè¯æˆåŠŸ: {tool['name']}",
                    tool_name=tool["name"],
                    tool_description=tool.get("description", ""),
                    validation_status="success"
                )
                logger.info(f"ä¸­æ–‡æ—¥å¿—: {tool_valid_log['data']['message']}")
            else:
                failed_tools.append(tool["name"])
                logger.warning("Tool (%s) is not available", tool["name"])
                
                # å·¥å…·éªŒè¯å¤±è´¥æ—¥å¿—
                tool_invalid_log = generate_chinese_log(
                    "tool_validation_failed",
                    f"âŒ å·¥å…·éªŒè¯å¤±è´¥: {tool['name']} ä¸åœ¨å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­",
                    tool_name=tool["name"],
                    validation_status="failed",
                    available_tools=list(agent_manager.available_tools.keys())[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªé¿å…æ—¥å¿—è¿‡é•¿
                )
                logger.warning(f"ä¸­æ–‡æ—¥å¿—: {tool_invalid_log['data']['message']}")
        
        # å·¥å…·é€‰æ‹©å®Œæˆæ—¥å¿—
        tool_selection_complete_log = generate_chinese_log(
            "tool_selection_complete",
            f"ğŸ”§ å·¥å…·é€‰æ‹©å®Œæˆ: {len(validated_tools)}ä¸ªæˆåŠŸï¼Œ{len(failed_tools)}ä¸ªå¤±è´¥",
            validated_tools=validated_tools,
            failed_tools=failed_tools,
            total_requested=len(agent_spec["selected_tools"]),
            success_rate=f"{len(validated_tools)}/{len(agent_spec['selected_tools'])}"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {tool_selection_complete_log['data']['message']}")
                
        # åˆ›å»ºæ™ºèƒ½ä½“
        agent_creation_log = generate_chinese_log(
            "agent_creation_start",
            f"ğŸš€ å¼€å§‹åˆ›å»ºæ™ºèƒ½ä½“: {agent_spec['agent_name']}",
            agent_name=agent_spec["agent_name"],
            llm_type=agent_spec["llm_type"],
            tools_count=len(tools),
            user_id=state["user_id"]
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {agent_creation_log['data']['message']}")
                
        await agent_manager._create_agent_by_prebuilt(
            user_id=state["user_id"],
            name=agent_spec["agent_name"],
            nick_name=agent_spec["agent_name"],
            llm_type=agent_spec["llm_type"],
            tools=tools,
            prompt=agent_spec["prompt"],
            description=agent_spec["agent_description"],
        )
        
        # æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸæ—¥å¿—
        agent_created_log = generate_chinese_log(
            "agent_created_success",
            f"ğŸ‰ æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ: {agent_spec['agent_name']}",
            agent_name=agent_spec["agent_name"],
            creation_status="success",
            agent_capabilities=agent_spec["agent_description"],
            prompt_length=len(agent_spec["prompt"]),
            final_tools=validated_tools
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {agent_created_log['data']['message']}")
        
        state["TEAM_MEMBERS"].append(agent_spec["agent_name"])
        
        # å›¢é˜Ÿæ›´æ–°æ—¥å¿—
        team_update_log = generate_chinese_log(
            "team_updated",
            f"ğŸ‘¥ å›¢é˜Ÿæˆå‘˜å·²æ›´æ–°ï¼Œæ–°å¢æ™ºèƒ½ä½“: {agent_spec['agent_name']}",
            new_agent=agent_spec["agent_name"],
            total_team_members=len(state["TEAM_MEMBERS"]),
            current_team=state["TEAM_MEMBERS"]
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {team_update_log['data']['message']}")

    elif state["workflow_mode"] == "polish":
        # this will be support soon
        polish_log = generate_chinese_log(
            "polish_mode",
            "ğŸ”§ æ™ºèƒ½ä½“å·¥å‚è¿›å…¥æ‰“ç£¨æ¨¡å¼ï¼ˆæš‚æœªæ”¯æŒï¼‰",
            workflow_mode="polish",
            support_status="coming_soon"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {polish_log['data']['message']}")
        pass

    # å·¥å‚å®Œæˆæ—¥å¿—
    factory_complete_log = generate_chinese_log(
        "agent_factory_complete",
        f"âœ… æ™ºèƒ½ä½“å·¥å‚ä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡ç§»äº¤ç»™å‘å¸ƒå™¨",
        next_node="publisher",
        factory_output=f"æˆåŠŸåˆ›å»ºæ™ºèƒ½ä½“: {agent_spec['agent_name'] if 'agent_spec' in locals() else 'æ— '}",
        workflow_mode=state["workflow_mode"]
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {factory_complete_log['data']['message']}")

    return Command(
        update={
            "messages": [
                {
                    "content": f"New agent {agent_spec['agent_name']} created. \n",
                    "tool": "agent_factory",
                    "role": "assistant",
                }
            ],
            "new_agent_name": agent_spec["agent_name"],
            "agent_name": "agent_factory",
        },
        goto=goto,
    )


async def publisher_node(
    state: State,
) -> Command[Literal["agent_proxy", "agent_factory", "__end__"]]:
    """publisher node that decides which agent should act next."""
    logger.info("publisher evaluating next action in %s mode ", state["workflow_mode"])
    
    # å‘å¸ƒå™¨å¯åŠ¨æ—¥å¿—
    publisher_start_log = generate_chinese_log(
        "publisher_start",
        "ğŸ“¨ å‘å¸ƒå™¨å¯åŠ¨ï¼Œå¼€å§‹è¯„ä¼°ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹",
        workflow_mode=state["workflow_mode"],
        current_step=state.get("current_step", "unknown"),
        workflow_id=state.get("workflow_id", "unknown")
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {publisher_start_log['data']['message']}")

    if state["workflow_mode"] == "launch":
        cache.restore_system_node(state["workflow_id"], PUBLISHER, state["user_id"])
        
        # åº”ç”¨å‘å¸ƒå™¨æç¤ºè¯æ¨¡æ¿
        publisher_prompt_log = generate_chinese_log(
            "publisher_prompt",
            "ğŸ“‹ æ­£åœ¨åº”ç”¨å‘å¸ƒå™¨æç¤ºè¯æ¨¡æ¿ï¼Œå‡†å¤‡å†³ç­–ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹",
            prompt_template="publisher",
            llm_type=AGENT_LLM_MAP["publisher"]
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {publisher_prompt_log['data']['message']}")
        
        messages = apply_prompt_template("publisher", state)
        
        # è°ƒç”¨LLMè¿›è¡Œè·¯ç”±å†³ç­–
        routing_decision_log = generate_chinese_log(
            "publisher_routing",
            "ğŸ¤– æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œè·¯ç”±å†³ç­–ï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºç¡®ä¿å†³ç­–å‡†ç¡®æ€§",
            structured_output_type="Router",
            decision_stage="next_agent_selection"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {routing_decision_log['data']['message']}")
        
        response = await (
            get_llm_by_type(AGENT_LLM_MAP["publisher"])
            .with_structured_output(Router)
            .ainvoke(messages)
        )
        agent = response["next"]

        # è·¯ç”±å†³ç­–å®Œæˆæ—¥å¿—
        routing_complete_log = generate_chinese_log(
            "publisher_decision",
            f"ğŸ¯ å‘å¸ƒå™¨å†³ç­–å®Œæˆï¼Œä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: {agent}",
            next_agent=agent,
            decision_type="structured_routing",
            routing_successful=True
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {routing_complete_log['data']['message']}")

        if agent == "FINISH":
            goto = "__end__"
            logger.info("Workflow completed \n")
            
            # å·¥ä½œæµå®Œæˆæ—¥å¿—
            workflow_complete_log = generate_chinese_log(
                "workflow_complete",
                "ğŸ å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œæ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ",
                final_status="completed",
                total_steps_completed=state.get("step_count", "unknown"),
                workflow_id=state.get("workflow_id", "unknown")
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {workflow_complete_log['data']['message']}")
            
            cache.restore_node(
                state["workflow_id"], goto, state["initialized"], state["user_id"]
            )
            return Command(goto=goto, update={"next": goto})
        elif agent != "agent_factory":
            cache.restore_system_node(state["workflow_id"], agent, state["user_id"])
            goto = "agent_proxy"
            
            # ä»£ç†èŠ‚ç‚¹åˆ†å‘æ—¥å¿—
            proxy_dispatch_log = generate_chinese_log(
                "publisher_dispatch_proxy",
                f"ğŸ”„ å‘å¸ƒå™¨å°†ä»»åŠ¡åˆ†å‘ç»™ä»£ç†èŠ‚ç‚¹ï¼Œç›®æ ‡æ™ºèƒ½ä½“: {agent}",
                target_agent=agent,
                dispatch_type="agent_proxy",
                next_node="agent_proxy"
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {proxy_dispatch_log['data']['message']}")
        else:
            cache.restore_system_node(
                state["workflow_id"], "agent_factory", state["user_id"]
            )
            goto = "agent_factory"
            
            # æ™ºèƒ½ä½“å·¥å‚åˆ†å‘æ—¥å¿—
            factory_dispatch_log = generate_chinese_log(
                "publisher_dispatch_factory",
                "ğŸ­ å‘å¸ƒå™¨å°†ä»»åŠ¡åˆ†å‘ç»™æ™ºèƒ½ä½“å·¥å‚ï¼Œå‡†å¤‡åˆ›å»ºæ–°æ™ºèƒ½ä½“",
                target_node="agent_factory",
                dispatch_type="agent_creation",
                next_node="agent_factory"
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {factory_dispatch_log['data']['message']}")

        logger.info("publisher delegating to: %s ", agent)

        cache.restore_node(
            state["workflow_id"], agent, state["initialized"], state["user_id"]
        )

    elif state["workflow_mode"] in ["production", "polish"]:
        # todo add polish history
        production_mode_log = generate_chinese_log(
            "publisher_production_mode",
            f"âš™ï¸ å‘å¸ƒå™¨è¿è¡Œåœ¨{state['workflow_mode']}æ¨¡å¼",
            workflow_mode=state["workflow_mode"],
            mode_type="cached_execution"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {production_mode_log['data']['message']}")
        
        agent = cache.get_next_node(state["workflow_id"])
        if agent == "FINISH":
            goto = "__end__"
            logger.info("Workflow completed \n")
            
            # ç”Ÿäº§æ¨¡å¼å®Œæˆæ—¥å¿—
            production_complete_log = generate_chinese_log(
                "workflow_complete_production",
                f"ğŸ {state['workflow_mode']}æ¨¡å¼å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                workflow_mode=state["workflow_mode"],
                final_status="completed"
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {production_complete_log['data']['message']}")
            
            return Command(goto=goto, update={"next": goto})
        else:
            goto = "agent_proxy"
            
            # ç”Ÿäº§æ¨¡å¼ä»£ç†åˆ†å‘æ—¥å¿—
            production_dispatch_log = generate_chinese_log(
                "publisher_production_dispatch",
                f"ğŸ”„ {state['workflow_mode']}æ¨¡å¼ä¸‹åˆ†å‘ä»»åŠ¡ç»™æ™ºèƒ½ä½“: {agent}",
                target_agent=agent,
                workflow_mode=state["workflow_mode"],
                next_node="agent_proxy"
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {production_dispatch_log['data']['message']}")
    
    logger.info("publisher delegating to: %s", agent)
    
    # å‘å¸ƒå™¨å®Œæˆæ—¥å¿—
    publisher_complete_log = generate_chinese_log(
        "publisher_complete",
        f"âœ… å‘å¸ƒå™¨ä»»åŠ¡å®Œæˆï¼ŒæˆåŠŸåˆ†å‘ç»™: {agent}",
        delegated_to=agent,
        next_goto=goto,
        delegation_successful=True
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {publisher_complete_log['data']['message']}")

    return Command(
        goto=goto,
        update={
            "messages": [
                {
                    "content": f"Next step is delegating to: {agent}\n",
                    "tool": "publisher",
                    "role": "assistant",
                }
            ],
            "next": agent,
        },
    )


async def agent_proxy_node(state: State) -> Command[Literal["publisher", "__end__"]]:
    """æ™ºèƒ½ä½“ä»£ç†èŠ‚ç‚¹"""
    _agent = state["next"]
    
    # å¤„ç†_agentå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡çš„æƒ…å†µ
    if isinstance(_agent, str):
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œä»agent_managerä¸­è·å–æ™ºèƒ½ä½“å¯¹è±¡
        agent_name = _agent
        if agent_name not in agent_manager.available_agents:
            logger.error(f"æ™ºèƒ½ä½“ {agent_name} ä¸å­˜åœ¨")
            return Command(
                update={
                    "messages": [
                        {
                            "content": f"âŒ æ™ºèƒ½ä½“ {agent_name} ä¸å­˜åœ¨",
                            "tool": state["next"],
                            "role": "assistant",
                        }
                    ],
                    "processing_agent_name": agent_name,
                    "agent_name": agent_name,
                },
                goto="publisher",
    )
        _agent = agent_manager.available_agents[agent_name]
    else:
        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
        agent_name = _agent.agent_name
    
    # æ™ºèƒ½ä½“ä»£ç†å¼€å§‹æ—¥å¿—
    proxy_start_log = generate_chinese_log(
        "agent_proxy_start",
        f"ğŸ¯ æ™ºèƒ½ä½“ä»£ç†å¼€å§‹æ‰§è¡Œ: {agent_name}",
        agent_name=agent_name,
        workflow_mode=state.get("workflow_mode", "unknown"),
        user_id=state.get("user_id")
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {proxy_start_log['data']['message']}")

    # æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
    available_tools = []
    missing_tools = []
    
    for tool in _agent.selected_tools:
        if tool.name in agent_manager.available_tools:
            available_tools.append(agent_manager.available_tools[tool.name])
        else:
            missing_tools.append(tool.name)
            logger.warning(f"å·¥å…· {tool.name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
    
    if missing_tools:
        logger.warning(f"æ™ºèƒ½ä½“ {agent_name} ç¼ºå°‘å·¥å…·: {missing_tools}")
    
    if not available_tools:
        logger.error(f"æ™ºèƒ½ä½“ {agent_name} æ²¡æœ‰å¯ç”¨çš„å·¥å…·")
        return Command(
            update={
                "messages": [
                    {
                        "content": f"âŒ æ™ºèƒ½ä½“ {agent_name} æ‰§è¡Œå¤±è´¥ï¼šæ²¡æœ‰å¯ç”¨çš„å·¥å…·ã€‚ç¼ºå°‘çš„å·¥å…·ï¼š{missing_tools}",
                        "tool": state["next"],
                        "role": "assistant",
                    }
                ],
                "processing_agent_name": agent_name,
                "agent_name": agent_name,
            },
            goto="publisher",
        )

    react_creation_log = generate_chinese_log(
        "react_agent_creation",
        f"âš™ï¸ æ­£åœ¨åˆ›å»ºReActæ™ºèƒ½ä½“å®ä¾‹: {agent_name}",
        agent_name=agent_name,
        react_pattern="observation_thought_action",
        tools_integrated=len(available_tools)
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {react_creation_log['data']['message']}")

    agent = create_react_agent(
        get_llm_by_type(_agent.llm_type),
        tools=available_tools,
        prompt=apply_prompt(state, _agent.prompt),
    )

    # Create config with user_id for tool notifications
    config = {
        "configurable": {"user_id": state.get("user_id")},
        "recursion_limit": int(MAX_STEPS),
    }
    
    # æ™ºèƒ½ä½“æ‰§è¡Œå¼€å§‹æ—¥å¿—
    agent_execution_log = generate_chinese_log(
        "agent_execution_start",
        f"ğŸš€ æ™ºèƒ½ä½“å¼€å§‹æ‰§è¡Œä»»åŠ¡: {agent_name}",
        agent_name=agent_name,
        max_steps=int(MAX_STEPS),
        user_id=state.get("user_id"),
        execution_config=config
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {agent_execution_log['data']['message']}")

    try:
        # æ·»åŠ è¶…æ—¶æœºåˆ¶
        response = await asyncio.wait_for(
            agent.ainvoke(state, config=config),
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
    
    # æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆæ—¥å¿—
        agent_execution_complete_log = generate_chinese_log(
            "agent_execution_complete",
            f"âœ… æ™ºèƒ½ä½“ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {agent_name}",
            agent_name=agent_name,
            execution_status="completed",
            response_length=len(response["messages"][-1].content) if response.get("messages") else 0,
            final_message_preview=response["messages"][-1].content[:100] + "..." if response.get("messages") and len(response["messages"][-1].content) > 100 else response["messages"][-1].content if response.get("messages") else ""
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {agent_execution_complete_log['data']['message']}")

    except asyncio.TimeoutError:
            logger.error(f"æ™ºèƒ½ä½“ {agent_name} æ‰§è¡Œè¶…æ—¶")
            return Command(
                update={
                    "messages": [
                        {
                            "content": f"â° æ™ºèƒ½ä½“ {agent_name} æ‰§è¡Œè¶…æ—¶ï¼Œè¯·é‡è¯•æˆ–ç®€åŒ–éœ€æ±‚",
                            "tool": state["next"],
                            "role": "assistant",
                        }
                    ],
                "processing_agent_name": agent_name,
                "agent_name": agent_name,
            },
            goto="publisher",
        )
    except Exception as e:
        logger.error(f"æ™ºèƒ½ä½“ {agent_name} æ‰§è¡Œå‡ºé”™: {e}")
        return Command(
            update={
                "messages": [
                    {
                        "content": f"âŒ æ™ºèƒ½ä½“ {agent_name} æ‰§è¡Œå‡ºé”™: {str(e)}",
                        "tool": state["next"],
                        "role": "assistant",
                    }
                ],
                "processing_agent_name": agent_name,
                "agent_name": agent_name,
            },
            goto="publisher",
        )

    if state["workflow_mode"] == "launch":
        cache.restore_node(
            state["workflow_id"], _agent, state["initialized"], state["user_id"]
        )
        
        # ç¼“å­˜çŠ¶æ€ä¿å­˜æ—¥å¿—
        cache_save_log = generate_chinese_log(
            "cache_state_saved",
            f"ğŸ’¾ æ™ºèƒ½ä½“æ‰§è¡ŒçŠ¶æ€å·²ä¿å­˜åˆ°ç¼“å­˜: {agent_name}",
            agent_name=agent_name,
            workflow_mode="launch",
            cache_operation="restore_node"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {cache_save_log['data']['message']}")
    elif state["workflow_mode"] == "production":
        cache.update_stack(state["workflow_id"], state["user_id"])
        
        # ç”Ÿäº§æ¨¡å¼ç¼“å­˜æ›´æ–°æ—¥å¿—
        production_cache_log = generate_chinese_log(
            "production_cache_updated",
            f"ğŸ“Š ç”Ÿäº§æ¨¡å¼ç¼“å­˜å †æ ˆå·²æ›´æ–°: {agent_name}",
            agent_name=agent_name,
            workflow_mode="production",
            cache_operation="update_stack"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {production_cache_log['data']['message']}")

    # ä»£ç†èŠ‚ç‚¹å®Œæˆæ—¥å¿—
    proxy_complete_log = generate_chinese_log(
        "agent_proxy_complete",
        f"ğŸ¯ æ™ºèƒ½ä½“ä»£ç†ä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡è¿”å›å‘å¸ƒå™¨: {agent_name}",
        agent_name=agent_name,
        return_to="publisher",
        proxy_status="completed"
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {proxy_complete_log['data']['message']}")

    return Command(
        update={
            "messages": [
                {
                    "content": response["messages"][-1].content,
                    "tool": state["next"],
                    "role": "assistant",
                }
            ],
            "processing_agent_name": agent_name,
            "agent_name": agent_name,
        },
        goto="publisher",
    )


async def planner_node(state: State) -> Command[Literal["publisher", "__end__"]]:
    """Planner node that generate the full plan."""
    logger.info("Planner generating full plan in %s mode", state["workflow_mode"])
    
    # è§„åˆ’å™¨å¯åŠ¨æ—¥å¿—
    planner_start_log = generate_chinese_log(
        "planner_start",
        "ğŸ§  è§„åˆ’å™¨å¯åŠ¨ï¼Œå¼€å§‹åˆ†æç”¨æˆ·éœ€æ±‚å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’",
        workflow_mode=state["workflow_mode"],
        user_query=state.get("USER_QUERY", "")[:100] + "..." if len(state.get("USER_QUERY", "")) > 100 else state.get("USER_QUERY", ""),
        deep_thinking_mode=state.get("deep_thinking_mode", False),
        search_before_planning=state.get("search_before_planning", False)
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {planner_start_log['data']['message']}")

    content = ""
    goto = "publisher"

    if state["workflow_mode"] == "launch":
        # åº”ç”¨è§„åˆ’å™¨æç¤ºè¯æ¨¡æ¿
        planner_prompt_log = generate_chinese_log(
            "planner_prompt",
            "ğŸ“‹ æ­£åœ¨åº”ç”¨è§„åˆ’å™¨æç¤ºè¯æ¨¡æ¿ï¼Œå‡†å¤‡æ·±åº¦åˆ†æç”¨æˆ·éœ€æ±‚",
            prompt_template="planner",
            available_agents=len(state.get("TEAM_MEMBERS", [])),
            available_tools=len(state.get("TOOLS", "").split("\n")) if state.get("TOOLS") else 0
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {planner_prompt_log['data']['message']}")
        
        messages = apply_prompt_template("planner", state)
        llm = get_llm_by_type(AGENT_LLM_MAP["planner"])
        
        # æ·±åº¦æ€è€ƒæ¨¡å¼æ£€æŸ¥
        if state.get("deep_thinking_mode"):
            llm = get_llm_by_type("reasoning")
            deep_thinking_log = generate_chinese_log(
                "planner_deep_thinking",
                "ğŸ¤” å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼ï¼Œä½¿ç”¨æ¨ç†å‹LLMè¿›è¡Œå¤æ‚éœ€æ±‚åˆ†æ",
                reasoning_llm=True,
                enhanced_analysis=True
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {deep_thinking_log['data']['message']}")
        
        # è§„åˆ’å‰æœç´¢æ£€æŸ¥
        if state.get("search_before_planning"):
            search_before_log = generate_chinese_log(
                "planner_search_before",
                "ğŸ” å¯ç”¨è§„åˆ’å‰æœç´¢ï¼Œè·å–ç›¸å…³ä¿¡æ¯ä»¥æå‡è§„åˆ’è´¨é‡",
                search_enabled=True,
                search_query=state["messages"][-1]["content"][:100] + "..."
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {search_before_log['data']['message']}")
            
            config = {"configurable": {"user_id": state.get("user_id")}}
            searched_content = tavily_tool.invoke(
                {
                    "query": [
                        "".join(message["content"])
                        for message in state["messages"]
                        if message["role"] == "user"
                    ][0]
                },
                config=config,
            )
            
            # æœç´¢ç»“æœè·å–æ—¥å¿—
            search_results_log = generate_chinese_log(
                "planner_search_results",
                f"ğŸ“Š æœç´¢å®Œæˆï¼Œè·å¾—{len(searched_content)}æ¡ç›¸å…³ä¿¡æ¯",
                search_results_count=len(searched_content),
                search_titles=[elem.get('title', '') for elem in searched_content[:3]]  # åªæ˜¾ç¤ºå‰3ä¸ªæ ‡é¢˜
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {search_results_log['data']['message']}")
            
            messages = deepcopy(messages)
            messages[-1]["content"] += (
                f"\n\n# Relative Search Results\n\n{json.dumps([{'titile': elem['title'], 'content': elem['content']} for elem in searched_content], ensure_ascii=False)}"
            )
        
        cache.restore_system_node(state["workflow_id"], PLANNER, state["user_id"])
        
        # LLMè°ƒç”¨å¼€å§‹æ—¥å¿—
        llm_planning_log = generate_chinese_log(
            "planner_llm_call",
            "ğŸ¤– æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆè¯¦ç»†æ‰§è¡Œè®¡åˆ’",
            llm_type=llm.__class__.__name__,
            message_length=len(str(messages)),
            planning_stage="llm_generation"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {llm_planning_log['data']['message']}")
        
        response = llm.stream(messages)
        for chunk in response:
            if chunk.content:
                content += chunk.content  # type: ignore
        content = clean_response_tags(content)
        
        # è§„åˆ’ç”Ÿæˆå®Œæˆæ—¥å¿—
        planning_complete_log = generate_chinese_log(
            "planner_plan_generated",
            "âœ… æ‰§è¡Œè®¡åˆ’ç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨è§£æå’ŒéªŒè¯è®¡åˆ’ç»“æ„",
            plan_length=len(content),
            content_preview=content[:200] + "..." if len(content) > 200 else content
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {planning_complete_log['data']['message']}")
        
    elif state["workflow_mode"] == "production":
        # watch out the json style
        production_plan_log = generate_chinese_log(
            "planner_production_mode",
            "âš™ï¸ è§„åˆ’å™¨è¿è¡Œåœ¨ç”Ÿäº§æ¨¡å¼ï¼Œä½¿ç”¨ç¼“å­˜çš„æ‰§è¡Œè®¡åˆ’",
            workflow_mode="production",
            cache_source="planning_steps"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {production_plan_log['data']['message']}")
        
        content = json.dumps(
            cache.get_planning_steps(state["workflow_id"]), indent=4, ensure_ascii=False
        )

    elif state["workflow_mode"] == "polish" and state["polish_target"] == "planner":
        # this will be support soon
        polish_mode_log = generate_chinese_log(
            "planner_polish_mode",
            "ğŸ”§ è§„åˆ’å™¨è¿›å…¥æ‰“ç£¨æ¨¡å¼ï¼Œä¼˜åŒ–ç°æœ‰æ‰§è¡Œè®¡åˆ’",
            workflow_mode="polish",
            polish_target="planner",
            historical_plan_available=bool(state.get("historical_plan"))
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {polish_mode_log['data']['message']}")
        
        state["historical_plan"] = cache.get_planning_steps(state["workflow_id"])
        state["adjustment_instruction"] = state["polish_instruction"]

        messages = apply_prompt_template("planner_polishment", state)
        llm = get_llm_by_type(AGENT_LLM_MAP["planner"])
        if state.get("deep_thinking_mode"):
            llm = get_llm_by_type("reasoning")
        if state.get("search_before_planning"):
            config = {"configurable": {"user_id": state.get("user_id")}}
            searched_content = tavily_tool.invoke(
                {
                    "query": [
                        "".join(message["content"])
                        for message in state["messages"]
                        if message["role"] == "user"
                    ][0]
                },
                config=config,
            )
            messages = deepcopy(messages)
            messages[-1]["content"] += (
                f"\n\n# Relative Search Results\n\n{json.dumps([{'titile': elem['title'], 'content': elem['content']} for elem in searched_content], ensure_ascii=False)}"
            )

        response = await llm.ainvoke(messages)
        content = clean_response_tags(response.content)  # type: ignore
    
    # steps need to be stored in cache
    if state["workflow_mode"] in ["launch", "polish"]:
        try:
            # è§£æå’ŒéªŒè¯è§„åˆ’æ­¥éª¤
            steps_parsing_log = generate_chinese_log(
                "planner_parse_steps",
                "ğŸ” æ­£åœ¨è§£æè§„åˆ’æ­¥éª¤JSONç»“æ„",
                parsing_stage="json_validation",
                content_length=len(content)
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {steps_parsing_log['data']['message']}")
            
            steps_obj = json.loads(content)
            steps = steps_obj.get("steps", [])
            
            # è§„åˆ’æ­¥éª¤è§£ææˆåŠŸæ—¥å¿—
            steps_parsed_log = generate_chinese_log(
                "planner_steps_parsed",
                f"âœ… è§„åˆ’æ­¥éª¤è§£ææˆåŠŸï¼Œå…±{len(steps)}ä¸ªæ‰§è¡Œæ­¥éª¤",
                total_steps=len(steps),
                step_agents=[step.get("agent_name") for step in steps],
                plan_title=steps_obj.get("title", ""),
                new_agents_needed=len(steps_obj.get("new_agents_needed", []))
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {steps_parsed_log['data']['message']}")
            
            cache.restore_planning_steps(state["workflow_id"], steps, state["user_id"])
            
            # ç¼“å­˜æ­¥éª¤ä¿å­˜æ—¥å¿—
            cache_steps_log = generate_chinese_log(
                "planner_steps_cached",
                f"ğŸ’¾ æ‰§è¡Œæ­¥éª¤å·²ä¿å­˜åˆ°ç¼“å­˜ï¼Œå·¥ä½œæµå¯ä»¥å¼€å§‹æ‰§è¡Œ",
                workflow_id=state["workflow_id"],
                steps_cached=len(steps),
                cache_operation="restore_planning_steps"
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {cache_steps_log['data']['message']}")
            
        except json.JSONDecodeError:
            logger.warning("Planner response is not a valid JSON \n")
            
            # JSONè§£æå¤±è´¥æ—¥å¿—
            json_error_log = generate_chinese_log(
                "planner_json_error",
                "âŒ è§„åˆ’å™¨å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå·¥ä½œæµå°†ç»ˆæ­¢",
                error_type="json_decode_error",
                content_preview=content[:200] + "..." if len(content) > 200 else content,
                workflow_termination=True
            )
            logger.error(f"ä¸­æ–‡æ—¥å¿—: {json_error_log['data']['message']}")
            
            goto = "__end__"
        cache.restore_system_node(state["workflow_id"], goto, state["user_id"])
    
    # è§„åˆ’å™¨å®Œæˆæ—¥å¿—
    planner_complete_log = generate_chinese_log(
        "planner_complete",
        f"ğŸ¯ è§„åˆ’å™¨ä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡ç§»äº¤ç»™: {goto}",
        next_node=goto,
        planning_status="completed" if goto == "publisher" else "terminated",
        workflow_mode=state["workflow_mode"]
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {planner_complete_log['data']['message']}")
    
    return Command(
        update={
            "messages": [{"content": content, "tool": "planner", "role": "assistant"}],
            "agent_name": "planner",
            "full_plan": content,
        },
        goto=goto,
    )


async def coordinator_node(state: State) -> Command[Literal["planner", "travel_planner", "__end__"]]:
    """Coordinator node that communicate with customers."""
    logger.info("Coordinator talking. \n")
    
    # åè°ƒå™¨å¯åŠ¨æ—¥å¿—
    coordinator_start_log = generate_chinese_log(
        "coordinator_start",
        "ğŸ¯ åè°ƒå™¨å¯åŠ¨ï¼Œå¼€å§‹åˆ†æç”¨æˆ·è¾“å…¥å¹¶å†³å®šå¤„ç†è·¯å¾„",
        user_query=state.get("USER_QUERY", "")[:100] + "..." if len(state.get("USER_QUERY", "")) > 100 else state.get("USER_QUERY", ""),
        workflow_mode=state.get("workflow_mode", "unknown"),
        user_id=state.get("user_id", "unknown")
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {coordinator_start_log['data']['message']}")

    goto = "__end__"
    content = ""

    # åº”ç”¨åè°ƒå™¨æç¤ºè¯æ¨¡æ¿
    coordinator_prompt_log = generate_chinese_log(
        "coordinator_prompt",
        "ğŸ“‹ æ­£åœ¨åº”ç”¨åè°ƒå™¨æç¤ºè¯æ¨¡æ¿ï¼Œå‡†å¤‡è¿›è¡Œæ™ºèƒ½åˆ†ç±»",
        prompt_template="coordinator",
        classification_protocols=2,  # Protocol 1: ç›´æ¥å›å¤, Protocol 2: ä»»åŠ¡ç§»äº¤
        llm_type=AGENT_LLM_MAP["coordinator"]
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {coordinator_prompt_log['data']['message']}")

    messages = apply_prompt_template("coordinator", state)
    
    # LLMè°ƒç”¨è¿›è¡Œåˆ†ç±»å†³ç­–
    classification_log = generate_chinese_log(
        "coordinator_classification",
        "ğŸ¤– æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†ç±»å†³ç­–",
        decision_stage="protocol_selection",
        input_analysis="user_intent_classification"
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {classification_log['data']['message']}")
    
    response = await get_llm_by_type(AGENT_LLM_MAP["coordinator"]).ainvoke(messages)
    if state["workflow_mode"] == "launch":
        cache.restore_system_node(state["workflow_id"], COORDINATOR, state["user_id"])

    content = clean_response_tags(response.content)  # type: ignore
    
    # åˆ†ç±»ç»“æœåˆ†æ
    if "handover_to_planner" in content:
        # ğŸ”„ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºæ—…æ¸¸ç›¸å…³ä»»åŠ¡
        user_query = state.get("USER_QUERY", "")
        travel_keywords = ["æ—…æ¸¸", "æ—…è¡Œ", "è¡Œç¨‹", "æ™¯ç‚¹", "æ”»ç•¥", "è®¡åˆ’", "è§„åˆ’", "å‡ºæ¸¸", "åº¦å‡", "ç©", "æ¸¸è§ˆ", "å‚è§‚", "ä½å®¿", "äº¤é€š", "å»", "åˆ°", "travel", "trip", "visit", "tour", "vacation", "holiday"]
        is_travel_related = any(keyword in user_query for keyword in travel_keywords)
        
        if is_travel_related:
            goto = "travel_planner"
            # Protocol 2: æ—…æ¸¸ä»»åŠ¡ç§»äº¤æ—¥å¿—
            handover_log = generate_chinese_log(
                "coordinator_travel_handover",
                "ğŸ—ºï¸ åè°ƒå™¨å†³ç­–: Protocol 2 - æ—…æ¸¸ä»»åŠ¡ç§»äº¤ç»™æ—…æ¸¸è§„åˆ’å™¨",
                protocol_selected=2,
                decision_type="travel_task",
                handover_target="travel_planner",
                task_complexity="requires_travel_planning"
            )
        else:
            goto = "planner"
            # Protocol 2: é€šç”¨ä»»åŠ¡ç§»äº¤æ—¥å¿—
            handover_log = generate_chinese_log(
                "coordinator_handover",
                "ğŸ”„ åè°ƒå™¨å†³ç­–: Protocol 2 - ä»»åŠ¡ç§»äº¤ç»™æ ‡å‡†è§„åˆ’å™¨",
                protocol_selected=2,
                decision_type="complex_task",
                handover_target="planner",
                task_complexity="requires_planning"
            )
        
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {handover_log['data']['message']}")
    else:
        # Protocol 1: ç›´æ¥å›å¤æ—¥å¿—
        direct_reply_log = generate_chinese_log(
            "coordinator_direct_reply",
            "ğŸ’¬ åè°ƒå™¨å†³ç­–: Protocol 1 - ç›´æ¥å›å¤ç”¨æˆ·",
            protocol_selected=1,
            decision_type="simple_task",
            response_type="direct_answer",
            response_preview=content[:100] + "..." if len(content) > 100 else content
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {direct_reply_log['data']['message']}")
    
    if state["workflow_mode"] == "launch":
        cache.restore_system_node(state["workflow_id"], "planner", state["user_id"])
    
    # åè°ƒå™¨å®Œæˆæ—¥å¿—
    coordinator_complete_log = generate_chinese_log(
        "coordinator_complete",
        f"âœ… åè°ƒå™¨ä»»åŠ¡å®Œæˆï¼Œé€‰æ‹©çš„å¤„ç†è·¯å¾„: {goto}",
        selected_protocol=2 if goto == "planner" else 1,
        next_node=goto,
        coordination_successful=True
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {coordinator_complete_log['data']['message']}")
    
    return Command(
        update={
            "messages": [
                {"content": content, "tool": "coordinator", "role": "assistant"}
            ],
            "agent_name": "coordinator",
        },
        goto=goto,
    )


def build_graph():
    """Build and return the agent workflow graph."""
    workflow = AgentWorkflow()
    workflow.add_node("coordinator", coordinator_node)  # type: ignore
    workflow.add_node("planner", planner_node)  # type: ignore
    workflow.add_node("publisher", publisher_node)  # type: ignore
    workflow.add_node("agent_factory", agent_factory_node)  # type: ignore
    workflow.add_node("agent_proxy", agent_proxy_node)  # type: ignore
    
    # ğŸ”„ æ–°å¢ï¼šæ—…æ¸¸ä¸“ç”¨èŠ‚ç‚¹
    workflow.add_node("travel_planner", travel_planner_node)  # type: ignore

    workflow.set_start("coordinator")
    return workflow.compile()
