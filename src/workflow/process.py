import logging
import hashlib
import asyncio
from typing import Any
from collections.abc import AsyncGenerator
from src.workflow import build_graph, agent_factory_graph
from src.manager import agent_manager
from src.interface.agent import TaskType
from rich.console import Console
from src.interface.agent import State
from src.service.env import USE_BROWSER
from src.workflow.cache import workflow_cache as cache
from src.workflow.graph import CompiledWorkflow
from src.interface.agent import WorkMode
from src.utils.chinese_names import (
    generate_chinese_log,
    format_agent_progress_log,
    get_agent_chinese_name
)
import re

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)

console = Console()


def enable_debug_logging():
    """Enable debug level logging for more detailed execution information."""
    logging.getLogger("src").setLevel(logging.DEBUG)


def is_travel_related_task(messages: list) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºæ—…æ¸¸ç›¸å…³ä»»åŠ¡"""
    travel_keywords = [
        # æ—…æ¸¸æ´»åŠ¨å…³é”®è¯
        "æ—…æ¸¸", "æ—…è¡Œ", "å‡ºè¡Œ", "åº¦å‡", "è¡Œç¨‹", "æ™¯ç‚¹", "æœºç¥¨", "é…’åº—", 
        "ä½å®¿", "é¢„è®¢", "æ”»ç•¥", "è‡ªç”±è¡Œ", "è·Ÿå›¢", "å¯¼æ¸¸", "é—¨ç¥¨",
        "å¥½ç©", "æ¨è", "å¿…å»", "å€¼å¾—", "è‘—å", "ç‰¹è‰²", "ç¾é£Ÿ", "æ–‡åŒ–",
        
        # ä¸­å›½ä¸»è¦åŸå¸‚
        "åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æˆéƒ½", "é‡åº†", "æ­å·", "è¥¿å®‰",
        "å—äº¬", "æ­¦æ±‰", "å¤©æ´¥", "è‹å·", "é•¿æ²™", "é’å²›", "å¤§è¿", "å¦é—¨",
        "æ˜†æ˜", "å“ˆå°”æ»¨", "æ²ˆé˜³", "é•¿æ˜¥", "çŸ³å®¶åº„", "å¤ªåŸ", "å‘¼å’Œæµ©ç‰¹",
        "æµå—", "éƒ‘å·", "åˆè‚¥", "å—æ˜Œ", "ç¦å·", "æµ·å£", "å—å®", "è´µé˜³",
        "å…°å·", "è¥¿å®", "é“¶å·", "ä¹Œé²æœ¨é½", "æ‹‰è¨",
        
        # ä¸­å›½ä¸»è¦çœä»½å’Œåœ°åŒº
        "æ–°ç–†", "è¥¿è—", "äº‘å—", "æµ·å—", "å››å·", "å¹¿ä¸œ", "æµ™æ±Ÿ", "æ±Ÿè‹",
        "å±±ä¸œ", "æ²³å—", "æ¹–åŒ—", "æ¹–å—", "é™•è¥¿", "å®‰å¾½", "æ±Ÿè¥¿", "ç¦å»º",
        "å¹¿è¥¿", "è´µå·", "ç”˜è‚ƒ", "æ²³åŒ—", "å±±è¥¿", "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ",
        "å†…è’™å¤", "å®å¤", "é’æµ·", "é¦™æ¸¯", "æ¾³é—¨", "å°æ¹¾",
        
        # å›½é™…çƒ­é—¨ç›®çš„åœ°
        "æ—¥æœ¬", "éŸ©å›½", "æ³°å›½", "æ–°åŠ å¡", "é©¬æ¥è¥¿äºš", "è¶Šå—", "æ³•å›½",
        "æ„å¤§åˆ©", "è‹±å›½", "å¾·å›½", "ç¾å›½", "æ¾³å¤§åˆ©äºš", "æ–°è¥¿å…°"
    ]
    
    # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯å†…å®¹
    content = " ".join([msg.get("content", "") if isinstance(msg, dict) else str(msg) for msg in messages])
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—…æ¸¸å…³é”®è¯
    matched_keywords = [keyword for keyword in travel_keywords if keyword in content]
    travel_score = len(matched_keywords)
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„æ—…æ¸¸è§„åˆ’è¦ç´ 
    has_dates = bool(re.search(r'\d{4}-\d{2}-\d{2}|[1-9]\d*å¤©|[1-9]\d*æ—¥', content))
    has_budget = bool(re.search(r'é¢„ç®—|è´¹ç”¨|èŠ±è´¹|å¤šå°‘é’±|\d+å…ƒ', content))
    has_travelers = bool(re.search(r'[1-9]\d*äºº|ä¸€å®¶|å¤«å¦»|æƒ…ä¾£|æœ‹å‹', content))
    
    planning_elements = sum([has_dates, has_budget, has_travelers])
    
    # åˆ¤æ–­é€»è¾‘ï¼šåŒ…å«æ—…æ¸¸å…³é”®è¯ æˆ– åŒ…å«å¤šä¸ªè§„åˆ’è¦ç´ 
    is_travel = travel_score >= 1 or planning_elements >= 2
    
    # è¯¦ç»†æ—¥å¿—
    logger.info(f"ğŸ” [ä»»åŠ¡æ£€æµ‹] å†…å®¹: '{content}'")
    logger.info(f"ğŸ” [ä»»åŠ¡æ£€æµ‹] åŒ¹é…çš„å…³é”®è¯: {matched_keywords}")
    logger.info(f"ğŸ” [ä»»åŠ¡æ£€æµ‹] æ—…æ¸¸å…³é”®è¯å¾—åˆ†: {travel_score}")
    logger.info(f"ğŸ” [ä»»åŠ¡æ£€æµ‹] è§„åˆ’è¦ç´ : æ—¥æœŸ={has_dates}, é¢„ç®—={has_budget}, äººæ•°={has_travelers}")
    logger.info(f"ğŸ” [ä»»åŠ¡æ£€æµ‹] è§„åˆ’è¦ç´ å¾—åˆ†: {planning_elements}")
    logger.info(f"ğŸ” [ä»»åŠ¡æ£€æµ‹] æœ€ç»ˆåˆ¤æ–­: {'âœ… æ—…æ¸¸ä»»åŠ¡' if is_travel else 'âŒ éæ—…æ¸¸ä»»åŠ¡'}")
    
    return is_travel


logger = logging.getLogger(__name__)

if USE_BROWSER:
    DEFAULT_TEAM_MEMBERS_DESCRIPTION = """
        - **`coder`**: Executes Python or Bash commands, performs mathematical calculations, and outputs a Markdown report. Must be used for all mathematical computations.
        - **`browser`**: Directly interacts with web pages, performing complex operations and interactions. You can also leverage `browser` to perform in-domain search, like Facebook, Instagram, Github, etc.
        - **`reporter`**: Write a professional report based on the result of each step.
        - **`agent_factory`**: Create a new agent based on the user's requirement.
        """
else:
    DEFAULT_TEAM_MEMBERS_DESCRIPTION = """
        - **`researcher`**: Uses search engines and web crawlers to gather information from the internet. Outputs a Markdown report summarizing findings. Researcher can not do math or programming.
        - **`coder`**: Executes Python or Bash commands, performs mathematical calculations, and outputs a Markdown report. Must be used for all mathematical computations.
        - **`reporter`**: Write a professional report based on the result of each step.
        - **`agent_factory`**: Create a new agent based on the user's requirement.
        """

TEAM_MEMBERS_DESCRIPTION_TEMPLATE = """
- **`{agent_name}`**: {agent_description}
"""
# Cache for coordinator messages
coordinator_cache = []
MAX_CACHE_SIZE = 2


async def run_agent_workflow(
    user_id: str,
    task_type: str,
    user_input_messages: list,
    debug: bool = False,
    deep_thinking_mode: bool = False,
    search_before_planning: bool = False,
    coor_agents: list[str] | None = None,
    polish_id: str = None,
    lap: int = 0,
    workmode: WorkMode = "launch",
    workflow_id: str = None,
    polish_instruction: str = None,
):
    """Run the agent workflow with the given user input.

    Args:
        user_input_messages: The user request messages
        debug: If True, enables debug level logging

    Returns:
        The final state after the workflow completes
    """
    if not workflow_id:
        if not polish_id:
            if workmode == "launch":
                msg = f"{user_id}_{task_type}_{user_input_messages}_{deep_thinking_mode}_{search_before_planning}_{coor_agents}"
                polish_id = hashlib.md5(msg.encode("utf-8")).hexdigest()
            else:
                polish_id = cache.get_latest_polish_id(user_id)

        workflow_id = f"{user_id}:{polish_id}"
    lap = cache.get_lap(workflow_id) if workmode != "launch" else 0

    if workmode != "production":
        lap = lap + 1

    cache.init_cache(
        user_id=user_id,
        mode=workmode,
        workflow_id=workflow_id,
        lap=lap,
        version=1,
        user_input_messages=user_input_messages.copy(),
        deep_thinking_mode=deep_thinking_mode,
        search_before_planning=search_before_planning,
        coor_agents=coor_agents,
    )

    if task_type == TaskType.AGENT_FACTORY:
        graph = agent_factory_graph()
    else:
        graph = build_graph()
    if not user_input_messages:
        raise ValueError("Input could not be empty")

    if debug:
        enable_debug_logging()

    logger.info(f"Starting workflow with user input: {user_input_messages}")
    
    # æ·»åŠ å·¥ä½œæµå¯åŠ¨ä¸­æ–‡æ—¥å¿—
    workflow_start_log = generate_chinese_log(
        "workflow_init",
        "ğŸš€ å¼€å§‹åˆå§‹åŒ–Cooragentå¤šæ™ºèƒ½ä½“å·¥ä½œæµ",
        workflow_id=workflow_id,
        user_id=user_id,
        task_type=task_type,
        user_input=user_input_messages[-1]["content"][:200] if user_input_messages else "",
        debug_mode=debug,
        deep_thinking_mode=deep_thinking_mode,
        search_before_planning=search_before_planning
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {workflow_start_log['data']['message']}")

    TEAM_MEMBERS_DESCRIPTION_TEMPLATE = """
    - **`{agent_name}`**: {agent_description}
    """
    TOOLS_DESCRIPTION_TEMPLATE = """
    - **`{tool_name}`**: {tool_description}
    """
    TOOLS_DESCRIPTION = """
    """
    TEAM_MEMBERS_DESCRIPTION = DEFAULT_TEAM_MEMBERS_DESCRIPTION
    TEAM_MEMBERS = ["agent_factory"]
    for agent in agent_manager.available_agents.values():
        if agent.user_id == "share":
            TEAM_MEMBERS.append(agent.agent_name)

        if agent.user_id == user_id or (coor_agents and agent.agent_name in coor_agents):
            TEAM_MEMBERS.append(agent.agent_name)

        if agent.user_id != "share":
            MEMBER_DESCRIPTION = TEAM_MEMBERS_DESCRIPTION_TEMPLATE.format(
                agent_name=agent.agent_name, agent_description=agent.description
            )
            TEAM_MEMBERS_DESCRIPTION += "\n" + MEMBER_DESCRIPTION

    for tool_name, tool in agent_manager.available_tools.items():
        TOOLS_DESCRIPTION += "\n" + TOOLS_DESCRIPTION_TEMPLATE.format(
            tool_name=tool_name, tool_description=tool.description
        )

    # è®°å½•å›¢é˜Ÿç»„å»ºå®Œæˆæ—¥å¿—
    team_setup_log = generate_chinese_log(
        "team_setup",
        f"ğŸ‘¥ æ™ºèƒ½ä½“å›¢é˜Ÿç»„å»ºå®Œæˆ: {len(TEAM_MEMBERS)}ä¸ªæ™ºèƒ½ä½“ï¼Œ{len(agent_manager.available_tools)}ä¸ªå·¥å…·",
        team_members=TEAM_MEMBERS,
        team_size=len(TEAM_MEMBERS),
        available_tools_count=len(agent_manager.available_tools),
        coordinator_agents=coor_agents or []
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {team_setup_log['data']['message']}")

    global coordinator_cache
    coordinator_cache = []
    global is_handoff_case
    is_handoff_case = False

    async for event_data in _process_workflow(
        graph,
        {
            "user_id": user_id,
            "TEAM_MEMBERS": TEAM_MEMBERS,
            "TEAM_MEMBERS_DESCRIPTION": TEAM_MEMBERS_DESCRIPTION,
            "TOOLS": TOOLS_DESCRIPTION,
            "USER_QUERY": user_input_messages[-1]["content"],
            "messages": user_input_messages,
            "deep_thinking_mode": deep_thinking_mode,
            "search_before_planning": search_before_planning,
            "workflow_id": workflow_id,
            "workflow_mode": workmode,
            "polish_instruction": polish_instruction,
            "initialized": False,
        },
    ):
        yield event_data


async def _process_workflow(
    workflow: CompiledWorkflow, initial_state: dict[str, Any]
) -> AsyncGenerator[dict[str, Any], None]:
    """å¤„ç†è‡ªå®šä¹‰å·¥ä½œæµçš„äº‹ä»¶æµ"""
    current_node = None

    workflow_id = initial_state["workflow_id"]
    
    # æ£€æµ‹æ˜¯å¦ä¸ºæ—…æ¸¸ä»»åŠ¡
    user_messages = initial_state.get("messages", [])
    if is_travel_related_task(user_messages):
        logger.info("ğŸ¯ æ£€æµ‹åˆ°æ—…æ¸¸ä»»åŠ¡ï¼Œå¯åŠ¨æ—…æ¸¸ä¸“ç”¨åè°ƒå™¨")
        
        # è¾“å‡ºæ—…æ¸¸å·¥ä½œæµå¼€å§‹æ—¥å¿—
        travel_workflow_start_log = generate_chinese_log(
            "travel_workflow_start", 
            "ğŸ§³ å¯åŠ¨æ—…æ¸¸ä¸“ç”¨æ™ºèƒ½ä½“å·¥ä½œæµ",
            workflow_id=workflow_id,
            user_query=initial_state.get("USER_QUERY", "")[:150]
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {travel_workflow_start_log['data']['message']}")
        
        yield {
            "event": "travel_workflow_start",
            "data": {"workflow_id": workflow_id, "message": "å¯åŠ¨æ—…æ¸¸ä¸“ç”¨å·¥ä½œæµ"},
        }
        
        # å¯¼å…¥å’Œè°ƒç”¨TravelCoordinator
        try:
            from src.workflow.travel_coordinator import TravelCoordinator
            
            # åˆ›å»ºTravelCoordinatorå®ä¾‹
            travel_coordinator = TravelCoordinator()
            
            # æ„å»ºStateå¯¹è±¡
            state = State({
                "messages": user_messages,
                "user_id": initial_state.get("user_id"),
                "workflow_id": workflow_id
            })
            
            # è°ƒç”¨æ—…æ¸¸åè°ƒå™¨
            logger.info("ğŸ§³ è°ƒç”¨TravelCoordinatorè¿›è¡Œæ—…æ¸¸è¯·æ±‚åˆ†æ")
            command = await travel_coordinator.coordinate_travel_request(state)
            
            yield {
                "event": "travel_coordinator_complete",
                "data": {
                    "workflow_id": workflow_id,
                    "routing_decision": command.goto,
                    "analysis": command.update if hasattr(command, 'update') else {}
                },
            }
            
            # å¦‚æœæ˜¯ç®€å•æŸ¥è¯¢ï¼Œç›´æ¥è¿”å›ç»“æœ
            if command.goto == "__end__":
                analysis = command.update.get("travel_analysis", {}) if hasattr(command, 'update') else {}
                
                # ç”Ÿæˆç®€å•æŸ¥è¯¢å“åº”
                simple_response = f"""
# æ—…æ¸¸ä¿¡æ¯æŸ¥è¯¢ç»“æœ

## ç›®çš„åœ°ï¼š{analysis.get('destination', 'æœªè¯†åˆ«')}
**åŒºåŸŸåˆ†ç±»**: {analysis.get('region', 'æœªçŸ¥')}

æ ¹æ®æ‚¨çš„æŸ¥è¯¢ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

### åŸºç¡€ä¿¡æ¯
- ç›®çš„åœ°ï¼š{analysis.get('destination', 'æœªè¯†åˆ«')}
- åœ°ç†åŒºåŸŸï¼š{'ä¸­å›½å¢ƒå†…' if analysis.get('region') == 'china' else 'å›½é™…ç›®çš„åœ°' if analysis.get('region') == 'international' else 'æœªç¡®å®š'}

### å»ºè®®
å¦‚æœæ‚¨éœ€è¦è¯¦ç»†çš„æ—…æ¸¸è§„åˆ’ï¼Œè¯·æä¾›ï¼š
1. å‡ºè¡Œæ—¶é—´ï¼ˆå…·ä½“æ—¥æœŸï¼‰
2. å‡ºè¡Œäººæ•°
3. é¢„ç®—èŒƒå›´
4. æ—…è¡Œåå¥½

è¿™æ ·æˆ‘å¯ä»¥ä¸ºæ‚¨åˆ¶å®šæ›´è¯¦ç»†çš„æ—…æ¸¸è®¡åˆ’ã€‚
"""
                
                yield {
                    "event": "workflow_complete",
                    "data": {
                        "workflow_id": workflow_id,
                        "result": simple_response,
                        "type": "simple_travel_query"
                    },
                }
                return
            
            # å¦‚æœæ˜¯å¤æ‚è§„åˆ’ï¼Œç»§ç»­æ‰§è¡Œæ ‡å‡†å·¥ä½œæµï¼Œä½†æ³¨å…¥æ—…æ¸¸ä¸Šä¸‹æ–‡
            elif command.goto == "planner" or command.goto == "travel_planner":
                if hasattr(command, 'update') and 'travel_context' in command.update:
                    travel_context = command.update['travel_context']
                    
                    # å°†æ—…æ¸¸ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°initial_state
                    initial_state['travel_context'] = travel_context
                    initial_state['is_travel_task'] = True
                    
                    logger.info(f"ğŸ§³ æ—…æ¸¸ä¸Šä¸‹æ–‡å·²æ³¨å…¥: å‡ºå‘åœ°={travel_context.get('departure')}, ç›®çš„åœ°={travel_context.get('destination')}, åŒºåŸŸ={travel_context.get('region')}")
                    
                    yield {
                        "event": "travel_context_injected", 
                        "data": {
                            "workflow_id": workflow_id,
                            "travel_context": travel_context
                        },
                    }
        
        except Exception as e:
            logger.error(f"TravelCoordinatorè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            yield {
                "event": "travel_coordinator_error",
                "data": {"workflow_id": workflow_id, "error": str(e)},
            }
    
    # è¾“å‡ºå·¥ä½œæµå¼€å§‹ä¸­æ–‡æ—¥å¿—
    workflow_start_log = generate_chinese_log(
        "workflow_start",
        "ğŸ¯ å¼€å§‹æ‰§è¡Œå¤šæ™ºèƒ½ä½“åä½œå·¥ä½œæµ",
        workflow_id=workflow_id,
        start_node=workflow.start_node,
        total_team_members=len(initial_state.get("TEAM_MEMBERS", [])),
        user_query=initial_state.get("USER_QUERY", "")[:150]
    )
    logger.info(f"ä¸­æ–‡æ—¥å¿—: {workflow_start_log['data']['message']}")
    
    yield {
        "event": "start_of_workflow",
        "data": {"workflow_id": workflow_id, "input": initial_state["messages"]},
    }

    try:
        current_node = workflow.start_node
        state = State(**initial_state)
        step_count = 0

        while current_node != "__end__":
            step_count += 1
            agent_name = current_node
            
            # æ™ºèƒ½ä½“å¯åŠ¨ä¸­æ–‡æ—¥å¿—
            agent_start_log = generate_chinese_log(
                "agent_start",
                format_agent_progress_log(agent_name, "start"),
                agent_name=agent_name,
                agent_chinese_name=get_agent_chinese_name(agent_name),
                step_number=step_count,
                workflow_id=workflow_id,
                workflow_progress=f"ç¬¬{step_count}æ­¥"
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {agent_start_log['data']['message']}")
            logger.info(f"Started node: {agent_name}")

            yield {
                "event": "start_of_agent",
                "data": {
                    "agent_name": agent_name,
                    "agent_id": f"{workflow_id}_{agent_name}_1",
                },
            }
            node_func = workflow.nodes[current_node]
            command = await node_func(state)

            if hasattr(command, "update") and command.update:
                for key, value in command.update.items():
                    if key != "messages":
                        state[key] = value

                    if key == "messages" and isinstance(value, list) and value:
                        # State ignores coordinator messages, which not only lacks contextual benefits
                        # but may also cause other unpredictable effects.
                        if agent_name != "coordinator":
                            state["messages"] += value
                        last_message = value[-1]
                        if "content" in last_message:
                            if agent_name == "coordinator":
                                content = last_message["content"]
                                if content.startswith("handover"):
                                    # mark handoff, do not send maesages
                                    global is_handoff_case
                                    is_handoff_case = True
                                    continue
                            if agent_name in ["planner", "coordinator", "agent_proxy"]:
                                content = last_message["content"]
                                chunk_size = 10  # send 10 words for each chunk
                                for i in range(0, len(content), chunk_size):
                                    chunk = content[i : i + chunk_size]
                                    if "processing_agent_name" in state:
                                        agent_name = state["processing_agent_name"]

                                    yield {
                                        "event": "messages",
                                        "agent_name": agent_name,
                                        "data": {
                                            "message_id": f"{workflow_id}_{agent_name}_msg_{i}",
                                            "delta": {"content": chunk},
                                        },
                                    }
                                    await asyncio.sleep(0.01)

                    if agent_name == "agent_factory" and key == "new_agent_name":
                        # è®°å½•æ–°æ™ºèƒ½ä½“åˆ›å»ºæ—¥å¿—
                        new_agent_log = generate_chinese_log(
                            "new_agent_created",
                            f"ğŸ‰ æˆåŠŸåˆ›å»ºæ–°æ™ºèƒ½ä½“: {get_agent_chinese_name(value)}",
                            new_agent_name=value,
                            new_agent_chinese_name=get_agent_chinese_name(value),
                            created_by="agent_factory",
                            workflow_id=workflow_id
                        )
                        logger.info(f"ä¸­æ–‡æ—¥å¿—: {new_agent_log['data']['message']}")
                        
                        yield {
                            "event": "new_agent_created",
                            "agent_name": value,
                            "data": {
                                "new_agent_name": value,
                                "agent_obj": agent_manager.available_agents[value],
                            },
                        }

            # æ™ºèƒ½ä½“å®Œæˆä¸­æ–‡æ—¥å¿—
            agent_complete_log = generate_chinese_log(
                "agent_complete",
                format_agent_progress_log(agent_name, "complete"),
                agent_name=agent_name,
                agent_chinese_name=get_agent_chinese_name(agent_name),
                next_node=command.goto,
                step_completed=step_count,
                workflow_id=workflow_id
            )
            logger.info(f"ä¸­æ–‡æ—¥å¿—: {agent_complete_log['data']['message']}")

            yield {
                "event": "end_of_agent",
                "data": {
                    "agent_name": agent_name,
                    "agent_id": f"{workflow_id}_{agent_name}_1",
                },
            }

            next_node = command.goto
            current_node = next_node

        # å·¥ä½œæµå®Œæˆä¸­æ–‡æ—¥å¿—
        workflow_complete_log = generate_chinese_log(
            "workflow_complete",
            "ğŸ‰ å¤šæ™ºèƒ½ä½“åä½œå·¥ä½œæµæ‰§è¡Œå®Œæˆ",
            workflow_id=workflow_id,
            total_steps=step_count,
            final_status="æˆåŠŸå®Œæˆ",
            execution_summary=f"å…±æ‰§è¡Œ{step_count}ä¸ªæ™ºèƒ½ä½“æ­¥éª¤"
        )
        logger.info(f"ä¸­æ–‡æ—¥å¿—: {workflow_complete_log['data']['message']}")

        yield {
            "event": "end_of_workflow",
            "data": {
                "workflow_id": workflow_id,
                "messages": [{"role": "user", "content": "workflow completed"}],
            },
        }

        cache.dump(workflow_id, initial_state["workflow_mode"])

    except Exception as e:
        import traceback

        # å·¥ä½œæµé”™è¯¯ä¸­æ–‡æ—¥å¿—
        workflow_error_log = generate_chinese_log(
            "workflow_error",
            f"âŒ å·¥ä½œæµæ‰§è¡Œé‡åˆ°é”™è¯¯: {str(e)}",
            workflow_id=workflow_id,
            error_type=type(e).__name__,
            error_details=str(e),
            current_node=current_node,
            error_location="workflow_execution"
        )
        logger.error(f"ä¸­æ–‡æ—¥å¿—: {workflow_error_log['data']['message']}")

        traceback.print_exc()
        logger.error("Error in Agent workflow: %s", str(e))
        yield {
            "event": "error",
            "data": {
                "workflow_id": workflow_id,
                "error": str(e),
            },
        }
